<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="generator" content="Astro v5.7.13"><meta name="commit" content="https://github.com/jonesded/developer-roadmap/commit/undefined"><title>Top 60+ Data Science Interview Questions and Answers</title><meta name="description" content="Ace your next Data Science interview with our Q&#38;As that are popular among hiring managers."><meta name="keywords" content="data science quiz, data science questions, data science interview questions, data science interview, data science test"><meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1.0, maximum-scale=3.0, minimum-scale=1.0"><meta http-equiv="Content-Language" content="en"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@kamrify"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image" content="https://assets.roadmap.sh/guest/data-science-interview-questions-and-answers-400hl.jpg"><meta property="og:image:alt" content="roadmap.sh"><meta property="og:site_name" content="roadmap.sh"><meta property="og:title" content="Top 60+ Data Science Interview Questions and Answers"><meta property="og:description" content="Ace your next Data Science interview with our Q&#38;As that are popular among hiring managers."><meta property="og:type" content="website"><meta property="og:url" content="https://hnmdevs.com/questions/data-science"><link rel="canonical" href="https://hnmdevs.com/questions/data-science"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="roadmap.sh"><meta name="application-name" content="roadmap.sh"><meta name="ahrefs-site-verification" content="04588b1b3d0118b4f973fa24f9df38ca6300d152cc26529a639e9a34d09c9880"><link rel="apple-touch-icon" sizes="180x180" href="/manifest/apple-touch-icon.png"><meta name="msapplication-TileColor" content="#101010"><meta name="theme-color" content="#848a9a"><link rel="manifest" href="/manifest/manifest.json"><link rel="icon" type="image/png" sizes="32x32" href="/manifest/icon32.png"><link rel="icon" type="image/png" sizes="16x16" href="/manifest/icon16.png"><link rel="shortcut icon" href="/manifest/favicon.ico" type="image/x-icon"><link rel="icon" href="/manifest/favicon.ico" type="image/x-icon"><link rel="preconnect" href="https://www.google-analytics.com/"><link rel="preconnect" href="https://api.roadmap.sh/"><!-- Google Tag Manager Start --><script>
      (function (w, d, s, l, i) {
        w[l] = w[l] || [];
        w[l].push({ 'gtm.start': new Date().getTime(), event: 'gtm.js' });
        var f = d.getElementsByTagName(s)[0],
          j = d.createElement(s),
          dl = l != 'dataLayer' ? '&l=' + l : '';
        j.async = true;
        j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
        f.parentNode.insertBefore(j, f);
      })(window, document, 'script', 'dataLayer', 'GTM-T66KC7S8');
    </script><!-- Google Tag Manager End --><script type="module" src="/_astro/Analytics.astro_astro_type_script_index_0_lang.CcEpoYr4.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-EZHDT2S2LF"></script> <script>
    // @ts-nocheck
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-EZHDT2S2LF');
</script><script async src="https://securepubads.g.doubleclick.net/tag/js/gpt.js"></script> <script async>
  const ignoredPages = [
    'login',
    'signup',
    'best-practices',
    'guides',
    'videos',
    'roadmaps',
    'community',
    'start-here',
    'ai-roadmaps',
    'ai',
    'teams',
    'about',
    'account',
    'projects',
    'questions',
    'guides',
    'advertise',
  ];

  function sanitizeSettingValue(value) {
    return (
      String(value)
        .trim()
        // Remove characters forbidden at https://support.google.com/admanager/answer/10020177.
        .replace(/'|\\|'|=|!|#|\*|~|;|\^|\(|\)|<|>|\[|\]|,|&/g, '')
        // Extra spaces aren't forbidden, but rarely desired.
        .replace(/\s+/, ' ')
        // The + sign is also forbidden, but is being replaced with 'and' instead.
        .replace('+', 'and')
        // Maximum length of 40 for values.
        .substring(0, 40)
    );
  }

  const page = window.location.pathname;
  const pageParts = page.split('/').filter(Boolean);

  const isRoadmapPage =
    pageParts.length === 1 && !ignoredPages.includes(pageParts[0]);
  const isBestPracticesPage =
    pageParts.length === 2 && pageParts[0] === 'best-practices';

  let adSettings = {};
  if (isRoadmapPage) {
    adSettings = {
      post_id: sanitizeSettingValue(pageParts[0]),
      page_type: 'roadmap',
      category: ['roadmap', sanitizeSettingValue(pageParts[0])],
    };
  } else if (isBestPracticesPage) {
    adSettings = {
      post_id: sanitizeSettingValue(pageParts[1]),
      page_type: 'best-practice',
      category: ['best-practice', sanitizeSettingValue(pageParts[1])],
    };
  }

  // @ts-nocheck
  window.googletag = window.googletag || { cmd: [] };
  googletag.cmd.push(function () {
    // Always use non-personalized ads
    googletag.pubads().setPrivacySettings({
      restrictDataProcessing: true,
      nonPersonalizedAds: true,
    });

    // Define ad slot and enable services
    googletag
      .defineSlot(
        '/22873384501/roadmap',
        ['fluid'],
        'div-gpt-ad-1742391132948-0',
      )
      .addService(googletag.pubads());

    // Set targeting for all ad slots on the page.
    for (let key in adSettings) {
      if (adSettings.hasOwnProperty(key)) {
        googletag.pubads().setTargeting(key, adSettings[key]);
      }
    }

    googletag.pubads().enableSingleRequest();
    googletag.enableServices();

    googletag.pubads().addEventListener('slotRenderEnded', function (e) {
      if (!e.isEmpty) {
        return;
      }

      const slotId = e.slot.getSlotElementId();
      if (!slotId) {
        return;
      }

      // If empty, hide the ad slot after a small delay.
      setTimeout(() => {
        const adContainer = document.getElementById(slotId);
        if (adContainer) {
          adContainer.style.display = 'none';
        }
      }, 1800);
    });
  });
</script><!-- OneTrust Cookies Consent Notice start for roadmap.sh --><script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" type="text/javascript" charset="UTF-8" data-domain-script="01977e0e-9a37-7b4a-aad2-8cf9247d94b6"></script> <script type="text/javascript">
  function OptanonWrapper() {}
</script> <!-- OneTrust Cookies Consent Notice end for roadmap.sh --><script type="text/javascript">
  (function (c, l, a, r, i, t, y) {
    c[a] =
      c[a] ||
      function () {
        (c[a].q = c[a].q || []).push(arguments);
      };
    t = l.createElement(r);
    t.async = 1;
    t.src = 'https://www.clarity.ms/tag/' + i;
    y = l.getElementsByTagName(r)[0];
    y.parentNode.insertBefore(t, y);
  })(window, document, 'clarity', 'script', 'qcw723i36o');
</script><script>
  // @ts-nocheck
  !(function (w, d) {
    if (!w.rdt) {
      var p = (w.rdt = function () {
        p.sendEvent
          ? p.sendEvent.apply(p, arguments)
          : p.callQueue.push(arguments);
      });
      p.callQueue = [];
      var t = d.createElement('script');
      (t.src = 'https://www.redditstatic.com/ads/pixel.js'), (t.async = !0);
      var s = d.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(t, s);
    }
  })(window, document);
  rdt('init', 'a2_ghq8846qpphp');
  rdt('track', 'PageVisit');
</script><script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/46095657.js?businessUnitId=2306992"></script><script async defer src="https://b174.roadmap.sh/script.js"></script><link rel="stylesheet" href="/_astro/billing.BjcgZc0E.css">
<style>code[class*=language-],pre[class*=language-]{color:#c5c8c6;text-shadow:0 1px rgba(0,0,0,.3);font-family:Inconsolata,Monaco,Consolas,Courier New,Courier,monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#1d1f21}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:#7c7c7c}.token.punctuation{color:#c5c8c6}.namespace{opacity:.7}.token.property,.token.keyword,.token.tag{color:#96cbfe}.token.class-name{color:#ffffb6;text-decoration:underline}.token.boolean,.token.constant{color:#9c9}.token.symbol,.token.deleted{color:#f92672}.token.number{color:#ff73fd}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#a8ff60}.token.variable{color:#c6c5fe}.token.operator{color:#ededed}.token.entity{color:#ffffb6;cursor:help}.token.url{color:#96cbfe}.language-css .token.string,.style .token.string{color:#87c38a}.token.atrule,.token.attr-value{color:#f9ee98}.token.function{color:#dad085}.token.regex{color:#e9c062}.token.important{color:#fd971f}.token.important,.token.bold{font-weight:700}.token.italic{font-style:italic}
</style><script>window.va = window.va || function () { (window.vaq = window.vaq || []).push(arguments); };
		var script = document.createElement('script');
		script.defer = true;
		script.src = '/_vercel/insights/script.js';
		var head = document.querySelector('head');
		head.appendChild(script);
	</script></head> <body class="flex min-h-screen flex-col"> <!-- Google Tag Manager (noscript) --> <noscript> <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T66KC7S8" height="0" width="0" style="display:none;visibility:hidden"></iframe> </noscript> <!-- End Google Tag Manager (noscript) -->  <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="ZURVaX" prefix="r13" component-url="/_astro/CourseAnnouncement.BkFOHY7G.js" component-export="CourseAnnouncement" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;CourseAnnouncement&quot;,&quot;value&quot;:true}" await-children><div class="sticky top-0 z-91 overflow-hidden transition-[height] duration-300 h-0"><a href="/courses/sql" class="flex items-center bg-yellow-400 py-1.5"><span class="container mx-auto flex items-center justify-start gap-2 text-center sm:justify-center sm:gap-4"><span class="flex items-center gap-1.5 text-xs font-medium text-black md:text-base"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-database hidden h-4 w-4 shrink-0 text-black sm:block" aria-hidden="true"><ellipse cx="12" cy="5" rx="9" ry="3"></ellipse><path d="M3 5V19A9 3 0 0 0 21 19V5"></path><path d="M3 12A9 3 0 0 0 21 12"></path></svg><span class="hidden sm:block">Master SQL with our new premium course</span><span class="block sm:hidden">Announcing our SQL course</span></span><span class="items-center gap-1.5 rounded-full bg-black px-2 py-0.5 text-xs font-medium tracking-wide text-white uppercase hover:bg-zinc-800 sm:px-3 sm:py-1"><span class="mr-1.5 hidden sm:inline">Start Learning</span><span class="mr-1.5 inline sm:hidden">Visit</span><span class="">→</span></span></span></a><button type="button" class="absolute top-1/2 right-3.5 -translate-y-1/2 rounded-lg px-1.5 py-1.5 text-gray-500 hover:bg-yellow-500 hover:text-gray-700"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x h-4 w-4" aria-hidden="true"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button></div><!--astro:end--></astro-island>   <div class="bg-slate-900 py-5 text-white sm:py-8"> <nav class="container flex items-center justify-between"> <div class="flex items-center gap-5"> <a class="flex items-center text-lg font-medium text-white" href="/" aria-label="HNM Devs"> <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 283 283" fill="#000" xmlns:v="https://vecta.io/nano"><path fill="#fff" d="M0 39C0 17.46 17.46 0 39 0h205c21.539 0 39 17.46 39 39v205c0 21.539-17.461 39-39 39H39c-21.54 0-39-17.461-39-39V39Z"></path><path d="M121.215 210.72c-1.867.56-4.854 1.12-8.96 1.68-3.92.56-8.027.84-12.32.84-4.107 0-7.84-.28-11.2-.84-3.174-.56-5.88-1.68-8.12-3.36s-4.014-3.92-5.32-6.72c-1.12-2.987-1.68-6.813-1.68-11.48v-84c0-4.293.746-7.933 2.24-10.92 1.68-3.173 4.013-5.973 7-8.4s6.626-4.573 10.92-6.44c4.48-2.053 9.24-3.827 14.28-5.32a106.176 106.176 0 0 1 15.68-3.36 95.412 95.412 0 0 1 16.24-1.4c8.96 0 16.053 1.773 21.28 5.32 5.226 3.36 7.84 8.96 7.84 16.8 0 2.613-.374 5.227-1.12 7.84-.747 2.427-1.68 4.667-2.8 6.72a133.1 133.1 0 0 0-12.04.56c-4.107.373-8.12.933-12.04 1.68s-7.654 1.587-11.2 2.52c-3.36.747-6.254 1.68-8.68 2.8v95.48zm45.172-22.4c0-7.84 2.426-14.373 7.28-19.6s11.48-7.84 19.88-7.84 15.026 2.613 19.88 7.84 7.28 11.76 7.28 19.6-2.427 14.373-7.28 19.6-11.48 7.84-19.88 7.84-15.027-2.613-19.88-7.84-7.28-11.76-7.28-19.6z"></path></svg> </a> <a href="/ai" class="group relative inline text-gray-400 hover:text-white sm:hidden">
AI Tutor
</a> <!-- Desktop navigation items --> <div class="hidden gap-5 sm:flex sm:items-center"> <astro-island uid="1ceDnR" prefix="r23" component-url="/_astro/NavigationDropdown.Dl-JRBNw.js" component-export="NavigationDropdown" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;NavigationDropdown&quot;,&quot;value&quot;:true}" await-children><div class="relative flex items-center"><button class="text-gray-400 hover:text-white" aria-label="Open Navigation Dropdown" aria-expanded="false"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5" aria-hidden="true"><path d="M4 12h16"></path><path d="M4 18h16"></path><path d="M4 6h16"></path></svg></button><div class="pointer-events-none invisible absolute left-0 top-full z-90 mt-2 w-48 min-w-[320px] -translate-y-1 rounded-lg bg-slate-800 py-2 opacity-0 shadow-xl transition-all duration-100" role="menu"><a href="/courses/sql" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-database inline-block h-5 w-5" aria-hidden="true"><ellipse cx="12" cy="5" rx="9" ry="3"></ellipse><path d="M3 5V19A9 3 0 0 0 21 19V5"></path><path d="M3 12A9 3 0 0 0 21 12"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">SQL Course<!-- --> <span class="text-[10px] font-bold text-black py-0.5 uppercase tracking-wider bg-yellow-400 rounded-full px-1.5 relative -top-0.5">New</span></span><span class="text-sm">Our premium SQL course</span></span></a><a href="/get-started" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right inline-block h-5 w-5" aria-hidden="true"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Get Started<!-- --> </span><span class="text-sm">Pick a path and get started</span></span></a><a href="/projects" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-folder-kanban inline-block h-5 w-5" aria-hidden="true"><path d="M4 20h16a2 2 0 0 0 2-2V8a2 2 0 0 0-2-2h-7.93a2 2 0 0 1-1.66-.9l-.82-1.2A2 2 0 0 0 7.93 3H4a2 2 0 0 0-2 2v13c0 1.1.9 2 2 2Z"></path><path d="M8 10v4"></path><path d="M12 10v2"></path><path d="M16 10v6"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Projects<!-- --> </span><span class="text-sm">Skill-up with real-world projects</span></span></a><a href="/guides" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-book-open-text inline-block h-5 w-5" aria-hidden="true"><path d="M12 7v14"></path><path d="M16 12h2"></path><path d="M16 8h2"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path><path d="M6 12h2"></path><path d="M6 8h2"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Guides<!-- --> </span><span class="text-sm">In-depth articles and tutorials</span></span></a><a href="/teams" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-users inline-block h-5 w-5" aria-hidden="true"><path d="M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2"></path><path d="M16 3.128a4 4 0 0 1 0 7.744"></path><path d="M22 21v-2a4 4 0 0 0-3-3.87"></path><circle cx="9" cy="7" r="4"></circle></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Teams<!-- --> </span><span class="text-sm">Collaborate with your team</span></span></a><a href="/advertise" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu inline-block h-5 w-5" aria-hidden="true"><path d="M4 12h16"></path><path d="M4 18h16"></path><path d="M4 6h16"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Advertise<!-- --> </span><span class="text-sm">Promote your product or service</span></span></a></div></div><!--astro:end--></astro-island> <astro-island uid="ZxkGTv" prefix="r24" component-url="/_astro/RoadmapDropdownMenu.KNH2CB9y.js" component-export="RoadmapDropdownMenu" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;RoadmapDropdownMenu&quot;,&quot;value&quot;:true}" await-children><div class="relative flex items-center"><button class="text-gray-400 hover:text-white" aria-label="Open Navigation Dropdown" aria-expanded="false"><span>Roadmaps<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down inline-block h-3 w-3" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></span></button><div class="pointer-events-none invisible absolute top-full left-0 z-90 mt-2 w-48 min-w-[320px] -translate-y-1 rounded-lg bg-slate-800 py-2 opacity-0 shadow-xl transition-all duration-100" role="menu"><a href="/roadmaps" class="group flex items-center gap-3 px-4 py-2.5 transition-colors mx-2 mb-1 rounded-md border border-slate-600 bg-slate-700 pl-2.5 text-gray-200 hover:bg-slate-600" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full transition-colors group-hover:bg-slate-500 group-hover:text-slate-100 bg-slate-500 text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-map inline-block h-5 w-5" aria-hidden="true"><path d="M14.106 5.553a2 2 0 0 0 1.788 0l3.659-1.83A1 1 0 0 1 21 4.619v12.764a1 1 0 0 1-.553.894l-4.553 2.277a2 2 0 0 1-1.788 0l-4.212-2.106a2 2 0 0 0-1.788 0l-3.659 1.83A1 1 0 0 1 3 19.381V6.618a1 1 0 0 1 .553-.894l4.553-2.277a2 2 0 0 1 1.788 0z"></path><path d="M15 5.764v15"></path><path d="M9 3.236v15"></path></svg></span><span class="flex flex-col"><span class="font-medium transition-colors group-hover:text-slate-100 text-white">Official Roadmaps<!-- --> </span><span class="text-sm">Made by subject matter experts</span></span></a><a href="/ai?format=roadmap" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sparkles inline-block h-5 w-5" aria-hidden="true"><path d="M9.937 15.5A2 2 0 0 0 8.5 14.063l-6.135-1.582a.5.5 0 0 1 0-.962L8.5 9.936A2 2 0 0 0 9.937 8.5l1.582-6.135a.5.5 0 0 1 .963 0L14.063 8.5A2 2 0 0 0 15.5 9.937l6.135 1.581a.5.5 0 0 1 0 .964L15.5 14.063a2 2 0 0 0-1.437 1.437l-1.582 6.135a.5.5 0 0 1-.963 0z"></path><path d="M20 3v4"></path><path d="M22 5h-4"></path><path d="M4 17v2"></path><path d="M5 18H3"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">AI Roadmaps<!-- --> </span><span class="text-sm">Generate roadmaps with AI</span></span></a><a href="/community" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe inline-block h-5 w-5" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Community Roadmaps<!-- --> </span><span class="text-sm">Made by community members</span></span></a></div></div><!--astro:end--></astro-island> <astro-island uid="Z1GJm6f" prefix="r25" component-url="/_astro/AIDropdownMenu.DCLM770k.js" component-export="AIDropdownMenu" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;AIDropdownMenu&quot;,&quot;value&quot;:true}" await-children><div class="relative flex items-center"><button class="text-gray-400 hover:text-white" aria-label="Open Navigation Dropdown" aria-expanded="false"><span class="group relative flex items-center gap-1 hover:text-white">AI Tutor<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down inline-block h-3 w-3" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></span></button><div class="pointer-events-none invisible absolute top-full left-0 z-90 mt-2 w-48 min-w-[320px] -translate-y-1 rounded-lg bg-slate-800 py-2 opacity-0 shadow-xl transition-all duration-100" role="menu"><a href="/ai" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-plus inline-block h-5 w-5" aria-hidden="true"><path d="M5 12h14"></path><path d="M12 5v14"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Create with AI<!-- --> </span><span class="text-sm">Learn something new with AI</span></span></a><a href="/ai/quiz" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-swords inline-block h-5 w-5" aria-hidden="true"><polyline points="14.5 17.5 3 6 3 3 6 3 17.5 14.5"></polyline><line x1="13" x2="19" y1="19" y2="13"></line><line x1="16" x2="20" y1="16" y2="20"></line><line x1="19" x2="21" y1="21" y2="19"></line><polyline points="14.5 6.5 18 3 21 3 21 6 17.5 9.5"></polyline><line x1="5" x2="9" y1="14" y2="18"></line><line x1="7" x2="4" y1="17" y2="20"></line><line x1="3" x2="5" y1="19" y2="21"></line></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Test my Skills<!-- --> </span><span class="text-sm">Test your skills with AI</span></span></a><a href="/ai/chat" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle inline-block h-5 w-5" aria-hidden="true"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Ask AI Tutor<!-- --> </span><span class="text-sm">Career, resume guidance, and more</span></span></a><a href="/ai/roadmap-chat" class="group flex items-center gap-3 px-4 py-2.5 text-gray-400 transition-colors hover:bg-slate-700" role="menuitem"><span class="flex h-[40px] w-[40px] items-center justify-center rounded-full bg-slate-600 transition-colors group-hover:bg-slate-500 group-hover:text-slate-100"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-map inline-block h-5 w-5" aria-hidden="true"><path d="M14.106 5.553a2 2 0 0 0 1.788 0l3.659-1.83A1 1 0 0 1 21 4.619v12.764a1 1 0 0 1-.553.894l-4.553 2.277a2 2 0 0 1-1.788 0l-4.212-2.106a2 2 0 0 0-1.788 0l-3.659 1.83A1 1 0 0 1 3 19.381V6.618a1 1 0 0 1 .553-.894l4.553-2.277a2 2 0 0 1 1.788 0z"></path><path d="M15 5.764v15"></path><path d="M9 3.236v15"></path></svg></span><span class="flex flex-col"><span class="font-medium text-slate-300 transition-colors group-hover:text-slate-100">Roadmap Chat<!-- --> </span><span class="text-sm">Chat with AI Tutor about a roadmap</span></span></a></div></div><!--astro:end--></astro-island> <script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event("astro:only"));})();</script><astro-island uid="27Okme" component-url="/_astro/UpgradeProButton.Bf6cPqyW.js" component-export="UpgradeProButton" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="only" opts="{&quot;name&quot;:&quot;UpgradeProButton&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> </div> </div> <ul class="hidden h-8 w-[172px] items-center justify-end gap-5 sm:flex"> <li data-guest-required class="hidden"> <a href="/login" class="text-gray-400 hover:text-white">Login</a> </li> <li class="flex items-center gap-2"> <astro-island uid="ZBGkSR" component-url="/_astro/AccountStreak.C5iwNbja.js" component-export="AccountStreak" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="only" opts="{&quot;name&quot;:&quot;AccountStreak&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> <astro-island uid="2hUg8c" component-url="/_astro/AccountDropdown.j6PP4KM4.js" component-export="AccountDropdown" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="only" opts="{&quot;name&quot;:&quot;AccountDropdown&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> <a data-guest-required class="flex hidden h-8 w-28 cursor-pointer items-center justify-center rounded-full bg-linear-to-r from-blue-500 to-blue-700 px-4 py-2 text-sm font-medium text-white hover:from-blue-500 hover:to-blue-600" href="/signup"> <span>Sign Up</span> </a> </li> </ul> <!-- Mobile Navigation Button --> <button class="block cursor-pointer text-gray-400 hover:text-gray-50 sm:hidden" aria-label="Menu" data-show-mobile-nav> <svg class="h-5 w-5" viewBox="0 0 24 24" focusable="false" aria-hidden="true">
  <path fill="currentColor" d="M 3 5 A 1.0001 1.0001 0 1 0 3 7 L 21 7 A 1.0001 1.0001 0 1 0 21 5 L 3 5 z M 3 11 A 1.0001 1.0001 0 1 0 3 13 L 21 13 A 1.0001 1.0001 0 1 0 21 11 L 3 11 z M 3 17 A 1.0001 1.0001 0 1 0 3 19 L 21 19 A 1.0001 1.0001 0 1 0 21 17 L 3 17 z"></path>
</svg> </button> <!-- Mobile Navigation Items --> <div class="fixed top-0 right-0 bottom-0 left-0 z-40 flex hidden items-center bg-slate-900" data-mobile-nav> <button data-close-mobile-nav class="absolute top-6 right-6 block cursor-pointer text-gray-400 hover:text-gray-50" aria-label="Close Menu"> <svg aria-hidden="true" class="w-5 h-5" fill="#c6c7c7" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd"
        d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z"
        clipRule="evenodd"></path>
</svg> </button> <ul class="flex w-full flex-col items-center gap-2 md:gap-3"> <li> <a href="/roadmaps" class="text-xl hover:text-blue-300 md:text-lg">
Roadmaps
</a> </li> <li> <a href="/ai" class="text-xl hover:text-blue-300 md:text-lg">
AI Tutor
</a> </li> <li> <a href="/guides" class="text-xl hover:text-blue-300 md:text-lg">
Guides
</a> </li> <!-- Links for logged in users --> <li data-auth-required class="hidden"> <a href="/account" class="text-xl hover:text-blue-300 md:text-lg">
Account
</a> </li> <li data-auth-required class="hidden"> <button data-logout-button class="text-xl text-red-300 hover:text-red-400 md:text-lg">
Logout
</button> </li> <li> <a data-guest-required href="/login" class="hidden text-xl text-white md:text-lg">
Login
</a> </li> <li> <a data-guest-required href="/signup" class="hidden text-xl text-green-300 hover:text-green-400 md:text-lg">
Sign Up
</a> </li> </ul> </div> </nav> </div> <script type="module" src="/_astro/Navigation.astro_astro_type_script_index_0_lang.DJCjCueH.js"></script>  <article class="lg:grid lg:max-w-full lg:grid-cols-[1fr_minmax(0,700px)_1fr]"> <div class="bg-linear-to-r from-gray-50 py-0 lg:col-start-3 lg:col-end-4 lg:row-start-1"> <astro-island uid="ZRQOh8" prefix="r17" component-url="/_astro/RelatedGuides.Bojw9AjP.js" component-export="RelatedGuides" renderer-url="/_astro/client.DWEMtbU6.js" props="{&quot;relatedTitle&quot;:[0],&quot;relatedGuides&quot;:[0,{}]}" ssr client="load" opts="{&quot;name&quot;:&quot;RelatedGuides&quot;,&quot;value&quot;:true}"></astro-island> <astro-island uid="rRSmH" prefix="r18" component-url="/_astro/TableOfContent.CA_NsO7k.js" component-export="TableOfContent" renderer-url="/_astro/client.DWEMtbU6.js" props="{&quot;toc&quot;:[1,[[0,{&quot;depth&quot;:[0,2],&quot;slug&quot;:[0,&quot;preparing-for-your-data-science-interview&quot;],&quot;text&quot;:[0,&quot;Preparing for your Data Science interview&quot;],&quot;children&quot;:[1,[]]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;test-with-flashcards&quot;],&quot;text&quot;:[0,&quot;Test yourself with Flashcards&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;core-concepts&quot;],&quot;text&quot;:[0,&quot;Core Concepts&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;statistics-and-probability&quot;],&quot;text&quot;:[0,&quot;Statistics and Probability&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;machine-learning-and-algorithms&quot;],&quot;text&quot;:[0,&quot;Machine Learning and Algorithms&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;coding-challenges&quot;],&quot;text&quot;:[0,&quot;Coding Challenges&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;real-business-scenarios&quot;],&quot;text&quot;:[0,&quot;Real Business Scenarios&quot;]}],[0,{&quot;depth&quot;:[0,2],&quot;children&quot;:[1,[]],&quot;slug&quot;:[0,&quot;advanced-topics&quot;],&quot;text&quot;:[0,&quot;Advanced Topics&quot;]}]]],&quot;slug&quot;:[0,&quot;questions-list&quot;],&quot;text&quot;:[0,&quot;Questions List&quot;]}]]]}" ssr client="load" opts="{&quot;name&quot;:&quot;TableOfContent&quot;,&quot;value&quot;:true}" await-children><div class="relative min-w-[250px] px-5 pt-0 max-lg:min-w-full max-lg:max-w-full max-lg:border-none max-lg:px-0 lg:pt-5 top-0 lg:sticky!"><h4 class="text-lg font-medium max-lg:hidden">In this article</h4><button class="flex w-full items-center justify-between gap-2 bg-gray-300 px-3 py-2 text-sm font-medium lg:hidden">Table of Contents<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down transform transition-transform" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button><ol class="mt-0.5 space-y-0 max-lg:absolute max-lg:top-full max-lg:mt-0 max-lg:w-full max-lg:bg-white max-lg:shadow-sm hidden lg:block"><li><a href="#preparing-for-your-data-science-interview" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1">Preparing for your Data Science interview</a></li><li><a href="#test-with-flashcards" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1">Test yourself with Flashcards</a></li><li><a href="#questions-list" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1">Questions List</a><ol class="my-0 ml-4 mt-1 space-y-0 max-lg:ml-0 max-lg:mt-0 max-lg:list-none"><li><a href="#core-concepts" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Core Concepts</a></li><li><a href="#statistics-and-probability" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Statistics and Probability</a></li><li><a href="#machine-learning-and-algorithms" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Machine Learning and Algorithms</a></li><li><a href="#coding-challenges" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Coding Challenges</a></li><li><a href="#real-business-scenarios" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Real Business Scenarios</a></li><li><a href="#advanced-topics" class="text-sm text-gray-500 no-underline hover:text-black max-lg:block max-lg:border-b max-lg:px-3 max-lg:py-1 max-lg:pl-8">Advanced Topics</a></li></ol></li></ol></div><!--astro:end--></astro-island> </div> <div class="col-start-2 col-end-3 row-start-1 mx-auto max-w-[700px] py-5 sm:py-10 lg:border-r"> <div class="container prose prose-xl prose-h2:mb-3 prose-h2:mt-10 prose-h2:scroll-mt-5 prose-h2:text-balance prose-h2:text-3xl prose-h3:mt-2 prose-h4:text-2xl prose-h3:scroll-mt-5 prose-h3:text-balance prose-h4:text-balance prose-h5:text-balance prose-h5:font-medium prose-blockquote:font-normal prose-code:bg-transparent prose-img:mt-1 sm:prose-h2:scroll-mt-10 sm:prose-h3:scroll-mt-10">  <h1 class="mb-3 text-4xl font-bold text-balance"> Top 60+ Data Science Interview Questions and Answers </h1> <p class="my-0 flex items-center justify-start text-sm text-gray-400"> <a href="/authors/william" class="inline-flex items-center font-medium underline-offset-2 hover:text-gray-600 hover:underline"> <img alt="William Imoh" src="/authors/william-imoh.jpg" class="mr-2 mb-0 inline h-5 w-5 rounded-full"> William Imoh </a> <span class="mx-2 hidden sm:inline">&middot;</span> <a class="hidden underline-offset-2 hover:text-gray-600 sm:inline" href="https://github.com/kamranahmedse/developer-roadmap/tree/master/src/data/question-groups/data-science" target="_blank">
Improve this Guide
</a> </p><p><img src="https://assets.roadmap.sh/guest/data-science-interview-questions-and-answers-400hl.jpg" alt="Top data science interview questions"></p>
<p>Data science interviews are in a league of their own. You’re expected to juggle statistics, programming, and business thinking, all at once. Even seasoned professionals need tailored preparation, as these interviews assess more than domain knowledge. They test how you think, solve problems, keep up with trends, and communicate your results on the spot.</p>
<p>This guide is comprehensive, with 60+ common data science interview questions and answers, and some common missteps that trip up experienced candidates. These questions are categorized into three key areas: conceptual knowledge (statistics, machine learning, data wrangling), coding skills (Python and SQL), and business communication (process explanation and solution alignment).</p>
<p>To help you practice smarter, I’ve included flashcards for active recall and self-testing. Want to go deeper? Check out the <a href="https://roadmap.sh/ai-data-scientist" target="_blank">data science roadmap</a> to strengthen the foundations behind your answers. Let’s start with the core data science concepts.</p>
<h2 id="preparing-for-your-data-science-interview">Preparing for your Data Science interview</h2>
<p>Ace your data science interview by keeping these tips in mind:</p>
<ul>
<li><strong>Strengthen your foundation</strong> in statistics, probability, and machine learning. Be clear on concepts like p-values, bias-variance tradeoff, and classification metrics.</li>
<li><strong>Practice coding</strong> in Python, R (optional), and SQL, especially tasks like data wrangling, joins, aggregations, and real-world feature engineering.</li>
<li><strong>Build hands-on projects</strong> that demonstrate your ability to apply models to real data. Tools like Kaggle, HackerRank, and GitHub are great places to showcase this.</li>
<li><strong>Learn to communicate your thinking.</strong> Practice explaining your process and trade-offs in business terms, not just technical ones.</li>
<li><strong>Study this guide</strong> to get familiar with the kinds of questions you’ll likely be asked. Use your own examples to make answers more relatable and memorable.</li>
<li><strong>Understand the company and its data use cases.</strong> Knowing their product, data stack, or industry challenges will help you tailor your answers and ask insightful questions.</li>
</ul> <h2 id="test-with-flashcards">Test yourself with Flashcards</h2> <p>
You can either use these flashcards or jump to the questions list
        section below to see them in a list format.
</p> <div class="mx-0 sm:-mb-32"> <astro-island uid="TshDF" prefix="r19" component-url="/_astro/QuestionsList.BFbCHfQD.js" component-export="QuestionsList" renderer-url="/_astro/client.DWEMtbU6.js" props="{&quot;groupId&quot;:[0,&quot;data-science&quot;],&quot;questions&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-correlation-and-causation&quot;],&quot;question&quot;:[0,&quot;What is the difference between correlation and causation?&quot;],&quot;answer&quot;:[0,&quot;Correlation is the statistical measure that shows a relationship between two variables. When one changes, the other changes as well, positively or negatively. However, this doesn&#39;t mean that one variable causes the other to change. Causation means that one variable directly causes a change in the other. It implies a cause-and-effect relationship, not just an association. Proving causation requires deeper analysis and additional evidence.\n\n**Example:** There&#39;s a correlation between cart abandonment and uninstall rates in a shopping app. Users who abandon their carts often end up uninstalling the app shortly after. But that doesn&#39;t mean abandoning a cart causes someone to uninstall the app. The real cause might be a frustrating purchase process with too many steps. That complexity leads to both behaviors: abandoning the cart and uninstalling the app. So, while there&#39;s a correlation, you can&#39;t say it&#39;s causation without looking deeper.\n\n![Correlation vs. causation](https://assets.roadmap.sh/guest/difference-between-correlation-and-causation-j92us.png) &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-role-of-statistics-in-data-science&quot;],&quot;question&quot;:[0,&quot;What is the role of statistics in data science?&quot;],&quot;answer&quot;:[0,&quot;The role of statistics in data science is to help data scientists understand and summarize data, uncover patterns, validate models, handle uncertainty (like missing or noisy data), and make evidence-based decisions.\n\n**For example**:\n\n- Mean and median summarize central tendencies.\n- Standard deviation and variance measure variability.\n- Hypothesis testing validates assumptions.\n- Regression analysis predicts relationships between variables.\n- Bayesian inference updates beliefs as new data comes in.\n\n**Use case**: A marketing team runs an A/B test to compare two email campaigns. Statistical methods help determine whether the difference in click-through rates is real or just a coincidence. &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-handle-missing-data&quot;],&quot;question&quot;:[0,&quot;How do you handle missing data?&quot;],&quot;answer&quot;:[0,&quot;After observing that my data set has missing values, I&#39;ll figure out how it occurs. Are they represented as **NaN,** **None,** empty strings, weird characters like -999, a combination of two or more, or something else?\n\n![How to handle missing data](https://assets.roadmap.sh/guest/how-do-you-handle-missing-data-vrptm.png)\n\nOnce I make sense of what my missing data looks like, I dig into why these values are missing, and they usually fall into three categories:\n\n- **Missing Completely At Random (MCAR):** No pattern, just random gaps. These are usually safe to drop, especially if there aren&#39;t many.\n\n    **Example:** In a survey dataset, 10% of income entries are missing due to a technical glitch that affected a random subset of responses. There&#39;s no pattern based on age, education, employment status, or anything else.\n\n- **Missing At Random (MAR):** This is when the missing data is related to *other observed variables*, but not to the income value itself.\n\n    **Example:** In the same dataset, 10% of `income` values are missing, mostly among respondents who are students. Here, missing data is related to the `occupation` variable, not the actual income value. Impute based on related features like `occupation`, `education level`, or `age`. Impute based on related features like `occupation`, `education level`, or `age`. Safe to drop or impute with mean/median since the missing data doesn&#39;t introduce bias.\n\n- **MNAR (Missing Not At Random):** The reason it&#39;s missing is tied to the value itself. \n\n    **Example:** If high spenders choose not to share income, that&#39;s tougher to handle and sometimes better tracked with a missingness flag. The probability of missingness increases with the income amount. Imputation is risky here. I&#39;ll consider flagging missingness with a binary indicator (`income_missing`) or using models that can account for MNAR, like EM algorithms or data augmentation techniques.\n\nOnce I know the type of missingness, I choose one of the following:\na. **Deletion (if safe):** \n\n- **Listwise:** Drop rows with missing values (only when missingness is random and small). \n- **Pairwise:** Use available values for calculations, such as correlations. \n- **Drop columns:** Remove low-value features with lots of missing data.\n\nb.  **Simple imputation:**\n\n- **Mean/Median/Mode:** Use for numeric or categorical columns, depending on distribution.\n- **Arbitrary values:** Fill with 0 or \&quot;Unknown\&quot; if it makes sense contextually.\n- **Forward/Backward fill:** Best for time series to keep temporal consistency.\n\nc.  **Advanced imputation:**\n\n- **KNN imputer:** Fills gaps by finding similar rows using distance metrics.\n- **Iterative imputer:** Builds a model with other columns to estimate missing values.\n- **Interpolation:** Good for numeric sequences, especially when data follows a trend.\n\nd.  **Use missingness as a feature:**\n\n- If the missing value could carry a signal, I add a binary indicator column (e.g., was_missing = 1).\n\ne.  **Oversampling or undersampling:**\n\n- If missing data causes class imbalance, I use resampling to maintain a fair target distribution.\n\n**Common pitfall**:\nFilling in values without understanding the pattern of missingness. For example, using mean imputation on MNAR data can introduce bias and weaken your model&#39;s predictive power. &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-univariate-bivariate-and-multivariate-analysis&quot;],&quot;question&quot;:[0,&quot;What is the difference between univariate, bivariate, and multivariate analysis?&quot;],&quot;answer&quot;:[0,&quot;Univariate analysis is all about looking at one variable on its own, with no comparisons, just understanding its distribution, central tendency, or spread. For example, I might look at the average test score in a class or the frequency of different grade ranges using histograms or summary statistics.\n\n![Univariate, bivariate, and multivariate analysis](https://assets.roadmap.sh/guest/understanding-univariate-bivariate-and-multivariate-analysis-in-data-science-s2663.png)\n\nBivariate analysis looks at the relationship between two variables, such as how students&#39; study time affects their test scores. To analyze this, I&#39;d use tools like correlation, scatter plots, or line graphs to identify trends or patterns.\n\nMultivariate analysis, on the other hand, deals with three or more variables at once. It focuses on understanding how multiple factors combine to influence an outcome. For example, I might explore how sleep hours, study time, and caffeine intake together impact test scores. In that case, I&#39;d use regression or a tree-based model to analyze the combined effect. &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-the-long-format-data-and-wide-format-data&quot;],&quot;question&quot;:[0,&quot;What is the difference between the long format data and wide format data?&quot;],&quot;answer&quot;:[0,&quot;The difference between long format data and wide format data comes down to how your data is structured. A wide format has values that do not repeat in the columns, while a long format has values that do repeat in the columns.\n\nIn wide format, you spread data across columns. Each variable (Jan, Feb, March) gets its own column. You&#39;ll usually see this in reports or dashboards.\n\n![Wide format data](https://assets.roadmap.sh/guest/wide-format-data-gxwrc.png)\n\nIn long format, data is stacked in rows. One column stores the values, and another column tells you what those values represent. This format is cleaner for grouped summaries and time series analysis.\n\n![Long format data](https://assets.roadmap.sh/guest/long-format-data-opeyt.png)\n\n**Use case:** Wide format is useful for reporting and making data visualizations. Long format is preferred for time series, grouped summaries, and plotting tools like Seaborn or ggplot.\n\n**Common pitfall:** Trying to perform group-level analysis on wide-format data without reshaping it first. &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-multicollinearity-and-how-do-you-detect-it&quot;],&quot;question&quot;:[0,&quot;What is multicollinearity, and how do you detect it?&quot;],&quot;answer&quot;:[0,&quot;Multicollinearity is when two or more independent variables in a regression model are highly correlated, meaning they tell similar stories. This makes it hard for the model to figure out which variable is actually influencing the target, leading to unreliable or unstable coefficient estimates. \n\nFor example, in a regression model looking at economic growth, common variables will be GDP, Unemployment Rate, and Consumer Spending. These variables are all related, and the model might not be as effective as it should be.\n\n**To detect multicollinearity use:**\n\n- **Correlation matrix:** A correlation matrix detects multicollinearity by visualizing the strength of relationships between variables. A general rule is that any correlation value above 0.6 indicates strong multicollinearity.\n- **Variance inflation factor (VIF):** VIF detects multicollinearity by giving a numerical value that indicates how much the variance of a regression coefficient is inflated due to multicollinearity. A VIF value greater than 5 indicates moderate multicollinearity, while values above 10 suggest severe multicollinearity.\n- **Condition index:** The condition index is a tool for detecting multicollinearity. Values above 10 indicate moderate multicollinearity, and values above 30 indicate severe multicollinearity. The condition index works by checking how much the independent variables are related to each other by examining the relationships between their eigenvalues.\n\n**Common pitfall:** Including highly correlated predictors without checking VIF may inflate model error and reduce stability. &quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-variance-in-data-science&quot;],&quot;question&quot;:[0,&quot;What is variance in data science?&quot;],&quot;answer&quot;:[0,&quot;Variance in data science measures the spread between numbers in a dataset. Simply put, it measures how far each number in the set is from the mean (average). It helps us understand how spread out or consistent the values are in a dataset.\n\n**Low variance example:**\nMean: (78 + 79 + 80 + 81 + 82) / 5 = 80&quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-do-you-understand-by-imbalanced-data&quot;],&quot;question&quot;:[0,&quot;What do you understand by imbalanced data?&quot;],&quot;answer&quot;:[0,&quot;Imbalanced data is a situation where the classes, labels, or categories in a dataset are not equally represented. In imbalanced datasets, one category has significantly more or fewer samples than the others. Imbalanced data refers to a common issue in supervised machine learning and deep learning where there is a non-uniform distribution of samples among different classes. This can lead to biased outcomes in models, such as those used in healthcare services, impacting their reliability and effectiveness.\n\nFor example, if you build an email spam detection model and your dataset contains 5% spam emails and 95% non-spam emails, the data is imbalanced toward non-spam. This imbalance can negatively affect the model&#39;s performance, especially in production, because it may achieve high accuracy by simply predicting the majority class while failing to detect spam effectively.&quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-approach-categorical-and-continuous-variables-differently-during-preprocessing&quot;],&quot;question&quot;:[0,&quot;How would you approach categorical and continuous variables differently during preprocessing?&quot;],&quot;answer&quot;:[0,&quot;A categorical variable is a column with fixed options based on qualities or labels like gender, age group, or education level. You can&#39;t do math on them directly, so during preprocessing, I usually apply one-hot encoding to turn those categories into binary columns the model can understand.\n\n![Categorical vs. continuous variables](https://assets.roadmap.sh/guest/categorical-variable-vs-continuous-variable-m1qz5.png)\n\nA continuous variable, on the other hand, can take on any value within a range like height, temperature, or speed. These are numeric, so you can run calculations on them. But before feeding them into a model, I scale them using normalization or standardization to keep all features on a similar range. This prevents one feature from overpowering the rest just because it has larger numbers.&quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;describe-how-you-would-transform-data-from-wide-format-to-long-format.-why-might-this-be-necessary&quot;],&quot;question&quot;:[0,&quot;Describe how you would transform data from wide format to long format. Why might this be necessary?&quot;],&quot;answer&quot;:[0,&quot;To transform data from wide format to long format, I usually use the **melt()** function in pandas to unpivot the columns into rows. It&#39;s especially useful when you have repeated measures across columns, like monthly sales or survey responses, and you want to make the data tidy for analysis or plotting.\n\nFor example, if I have a DataFrame where each column represents a month, I&#39;ll keep the identifier (like product name) as is, and melt the rest so each row shows one product-month-sales combo. This makes it easier to group, filter, or feed into models.&quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-combine-data-from-multiple-sources-with-inconsistent-formats&quot;],&quot;question&quot;:[0,&quot;How do you combine data from multiple sources with inconsistent formats?&quot;],&quot;answer&quot;:[0,&quot;When I combine data from different sources with inconsistent formats, the first thing I do is standardize everything: dates, column names, booleans, numbers, etc., so they all speak the same language. After doing that, I&#39;ll:\n\n- **Align schemas:** match columns across datasets. If one has extras, I drop or keep them depending on relevance.\n- **Unify categories:** I clean up inconsistencies like \&quot;Y\&quot; vs. \&quot;Yes\&quot; to avoid downstream issues.\n- **Tag the source:** I add a source column so I know where each row came from. This is super useful for tracking or debugging later.\n- **Merge or stack:** If the structure is the same, I **concat()**. If I&#39;m matching on something like customer ID, I go with a merge or join.\n- **Final clean-up:** I look for duplicates, mismatched types, or broken values post-merge and fix them.\n\nI avoid merging before checking data types or keys. That’s a fast track to lost or duplicated rows.&quot;],&quot;topics&quot;:[1,[[0,&quot;Core Concepts&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-central-limit-theorem-and-why-is-it-important&quot;],&quot;question&quot;:[0,&quot;What is the Central Limit Theorem, and why is it important?&quot;],&quot;answer&quot;:[0,&quot;The Central Limit Theorem (CLT) states that if you take enough random samples from any dataset, even if the data is skewed or messy, the average of those samples will start to form a bell-shaped or normal distribution. This only holds if the samples are random, independent, and large enough, usually 30 or more.\n\nWhy does this matter? Because once those averages form a normal shape, you can use all the tools from the normal distribution. You can calculate standard errors, build confidence intervals, run hypothesis tests, make estimates, and use z-scores, even if the original data wasn’t normal to begin with.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-type-i-and-type-ii-errors&quot;],&quot;question&quot;:[0,&quot;What is the difference between Type I and Type II errors?&quot;],&quot;answer&quot;:[0,&quot;The difference between Type I and Type II error is that Type I error rejects a true null hypothesis (a false positive), while Type II error fails to reject a false null hypothesis (a false negative).\n\n![Type I vs Type II error](https://assets.roadmap.sh/guest/difference-between-type-i-and-type-ii-errors-90mpj.png)\n\nLet&#39;s assume you&#39;re testing a new drug. The null hypothesis is that the drug doesn&#39;t work, and in reality, it indeed doesn&#39;t. A type I error occurs when your test says it does, but it doesn&#39;t; this is a false positive. A type II, on the other hand, is when the drug works in reality, but your tests say it doesn&#39;t: a false negative.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-a-p-value-how-do-you-interpret-it&quot;],&quot;question&quot;:[0,&quot;What is a p-value? How do you interpret it?&quot;],&quot;answer&quot;:[0,&quot;A p-value is a statistical measure that determines the significance of the result you got in a hypothesis test. A small p-value (&lt;0.05) indicates strong evidence that the null hypothesis is wrong, meaning you should reject it.\n\n![P-value interpretation](https://assets.roadmap.sh/guest/how-to-interpret-p-value-hzfqe.png)\n\nIf the probability of the p-value is greater than 0.05, there is not enough evidence to reject the null hypothesis. For example, if you conduct an experiment and the p-value is 0.03, you should reject the null hypothesis. &quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;explain-confidence-intervals-in-simple-terms.&quot;],&quot;question&quot;:[0,&quot;Explain confidence intervals in simple terms.&quot;],&quot;answer&quot;:[0,&quot;A confidence interval is a range of values that&#39;s likely to have the true value of a population parameter based on sample data. Let&#39;s say you surveyed a sample of high school teachers and found their average salary was $75,000. Since that&#39;s just a sample, you can&#39;t say for sure it reflects all teachers, but we can say:\n\n*\&quot;We&#39;re 95% confident that the real average salary for all teachers falls between $72,000 and $78,000.\&quot;*\n\nThe confidence interval is between $72,000 and $78,000. It gives us a buffer to account for uncertainty in our estimate.\n\n![Confidence intervals for teachers salaries](https://assets.roadmap.sh/guest/confidence-interval-for-teacher-salaries-mee1i.png)&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-a-probability-distribution-name-a-few-commonly-used-ones.&quot;],&quot;question&quot;:[0,&quot;What is a probability distribution? Name a few commonly used ones.&quot;],&quot;answer&quot;:[0,&quot;A probability distribution tells you how likely different possible outcomes are for a random event or experiment. It maps out the chances of different results happening. It’s a way of saying, “Here’s everything that could happen, and how often I expect each one to happen.”\n\nThe commonly used probability distributions are normal (bell curve), binomial, Poisson, and uniform distributions.\n\n**Common pitfall:** Different types of distributions need different types of analysis. Using the wrong type of distribution for analysis can lead to wrong results. Another common problem is assuming that data follow a normal distribution without testing for normality.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;when-would-you-use-a-t-test-vs.-a-z-test&quot;],&quot;question&quot;:[0,&quot;When would you use a t-test vs. a z-test?&quot;],&quot;answer&quot;:[0,&quot;The difference between a t-test and a z-test comes down to what you know about your data: the sample size and the population standard deviation.\n\n![t-test vs z-test](https://assets.roadmap.sh/guest/t-test-vs-z-test-wtm6x.png)\n\nUse a t-test when:\n\n- The sample size is small (usually n ≤ 30).\n- The population standard deviation is unknown.\n- You still want to compare means (sample vs. population or between two samples).\n\nUse a z-test when:\n\n- You know the population standard deviation.\n- Your sample size is large (typically n &gt; 30).\n- The data is roughly normally distributed.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-null-hypothesis-and-how-do-you-determine-whether-to-reject-it&quot;],&quot;question&quot;:[0,&quot;What is the null hypothesis, and how do you determine whether to reject it?&quot;],&quot;answer&quot;:[0,&quot;The null hypothesis (H₀) is the starting point and default assumption of every statistical analysis. The idea is that there&#39;s nothing happening in your data: no stories, no effect, no relationship between the variables you&#39;re testing until your data gives strong evidence to reject it.\n\n![When to reject null hypothesis](https://assets.roadmap.sh/guest/when-to-reject-null-hypothesis-rchdo.png)\n\nTo know whether to reject the null hypothesis, here&#39;s what I do:\n\nFirst, I set a significance level, usually 0.05. Then, I calculate the p-value. If the p-value is less than or equal to 0.05, I reject the null hypothesis because the result is statistically significant. If it&#39;s more than 0.05, I don&#39;t reject it because there isn&#39;t enough evidence.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;explain-the-central-limit-theorem-if-we-don&#39;t-assume-that-the-random-variables-are-identically-distributed-but-are-still-independent-with-finite-second-moments.&quot;],&quot;question&quot;:[0,&quot;Explain the Central Limit Theorem if we don&#39;t assume that the random variables are identically distributed but are still independent with finite second moments.&quot;],&quot;answer&quot;:[0,&quot;This is a curveball question because the interviewer isn&#39;t really asking about the classic CLT. They&#39;re testing your knowledge about the Lindeberg-Feller CLT.\n\nIn the classic CLT, all the variables are independent and from the same probability distribution (identically distributed). But here, the interviewer is saying: What if they&#39;re still independent but not identically distributed? Lindeberg-Feller helps in situations like this.\n\nIt states that as long as the variables are independent, have finite second moments (meaning their variances aren&#39;t huge), and no single variable dominates (the Lindeberg condition), the normalized sum of those variables will still approach a normal distribution. So, even with different distributions, if those conditions hold, the average still forms a bell curve.&quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;explain-the-long-tail-distribution-and-provide-three-examples-of-relevant-phenomena-that-have-long-tails.-why-are-they-important-in-classification-and-regression-problems&quot;],&quot;question&quot;:[0,&quot;Explain the long-tail distribution and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?&quot;],&quot;answer&quot;:[0,&quot;A long-tail distribution is a type of distribution where you group most of the data around the middle, but there are still many rare or unusual values that stretch far out to the sides (tail) and have a big impact.\n\n![Long-tail distribution](https://assets.roadmap.sh/guest/the-long-tail-t20gr.png)\n\n**Some examples are:**\n\n1. **Long-tail keywords in SEO**: A few high-volume keywords (like \&quot;shoes\&quot;) get massive search volume, but there&#39;s a long tail of specific, niche searches (like \&quot;waterproof hiking shoes for wide feet\&quot;) that collectively make up most of the search traffic. These long-tail keywords aren&#39;t often searched for, but they convert well.\n\n2. **Book sales**: Bestsellers like *Harry Potter* dominate the market, but tons of niche books (even classics like *Jane Austen*) sell steadily in the background. The collective sales of these less popular books often exceed those of the bestsellers.\n\n3. **Luxury bags**: A few brands are always trending. However, there&#39;s a long list of unique, lesser-known ones that still sell and matter to the market.\n\n**Why they&#39;re important in classification and regression problems:**\n\nLong-tail distributions can throw off model performance because most models are trained on the majority class, the \&quot;head,\&quot; and ignore rare but important events in the tail. This is risky in cases like fraud detection or churn modeling, where rare events matter most. They also affect Mean Squared Error, which squares the difference between predicted and actual values, so a few extreme errors from tail cases can blow up the score, even if your model does well overall.\n\nLong-tail distributions can create models that are biased toward the majority, skew errors, and cause you to miss rare events that matter. Handling them requires better sampling techniques and using loss functions that properly account for these rare but significant occurrences. &quot;],&quot;topics&quot;:[1,[[0,&quot;Statistics and Probability&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-supervised-unsupervised-and-reinforcement-learning&quot;],&quot;question&quot;:[0,&quot;What is the difference between supervised, unsupervised, and reinforcement learning?&quot;],&quot;answer&quot;:[0,&quot;The difference between supervised, unsupervised, and reinforcement learning lies in how the model learns. This table describes their contrasts and common use cases for each.\n\n| **Type of Learning**       | **Description**                                                                                                                                               | **Common Use Cases**                             |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ |\n| **Supervised Learning**    | Models are trained on labeled data, where each example includes an input and a known output. The model learns to predict the output for new, unseen inputs.   | Regression and classification tasks.             |\n| **Unsupervised Learning**  | Models are trained on unlabeled data. The goal is to find hidden patterns or structure in the data without explicit output labels.                            | Clustering, dimensionality, and reduction tasks. |\n| **Reinforcement Learning** | A model learns by trial and error, receiving rewards or penalties based on its actions. It aims to make a sequence of decisions to maximize reward over time. | Games, robotics, and AI decision-making systems. | &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;explain-the-bias-variance-tradeoff.&quot;],&quot;question&quot;:[0,&quot;Explain the bias-variance tradeoff.&quot;],&quot;answer&quot;:[0,&quot;The bias-variance tradeoff refers to the balance between a model&#39;s ability to learn patterns (low bias) and its ability to generalize to new data (low variance). Bias is the error made when the model makes strong assumptions about the data: high bias could lead to underfitting. Variance is the model&#39;s sensitivity to small fluctuations in the data, and high variance could lead to overfitting.\n\n![Bias-variance tradeoff](https://assets.roadmap.sh/guest/bias-variance-tradeoff-jc0mj.png) &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-cross-validation-and-why-is-it-important&quot;],&quot;question&quot;:[0,&quot;What is cross-validation, and why is it important?&quot;],&quot;answer&quot;:[0,&quot;Cross-validation is a technique for evaluating a model&#39;s performance on an individual dataset. It divides the dataset into subsets, usually the training, test, and validation sets. This process is repeated multiple times to ensure the model generalizes well to unseen data and to stop overfitting.\n\n![Cross-validating data](https://assets.roadmap.sh/guest/cross-validationing-data-uha2b.png) &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-overfitting-and-how-can-you-prevent-it&quot;],&quot;question&quot;:[0,&quot;What is overfitting, and how can you prevent it?&quot;],&quot;answer&quot;:[0,&quot;Overfitting in machine learning happens when the model learns from the training data too well, including non-relevant details. This leads the model to perform very well on the training data but poorly on other data.\n\n**Prevention techniques:**\n\n- **Regularization (L1/L2):** This method adds a penalty to large weights to keep the model from becoming too complex.\n- **Cross-validation:** This helps test the model on different slices of data to make sure it generalizes well.\n- **Pruning (for tree models):** Cuts back unnecessary branches that overcomplicate the model.\n- **Early stopping:** Stops training when performance stops improving on the validation set.\n- **Dropout (for neural nets):** This method randomly drops neurons during training so the network doesn&#39;t become too dependent on specific paths. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-decision-trees-work&quot;],&quot;question&quot;:[0,&quot;How do decision trees work?&quot;],&quot;answer&quot;:[0,&quot;A decision tree is a machine learning algorithm used for classification and regression tasks. It makes decisions by following a tree-like structure where internal nodes represent attribute tests, branches represent attribute values, and leaf nodes represent predictions.\n\n![Decision tree](https://assets.roadmap.sh/guest/decision-tree-y4hrk.png)\n\nDecision trees are versatile and are used for many machine learning tasks.\n\n**Example**: Loan approval decision tree\n\n- **Step 1 – Ask a question (Root Node)**: Is the applicant&#39;s credit score &gt; 700?\n  - If yes, go to Internal Node.\n  - If no, go to Leaf Node (Do not approve the loan).\n- **Step 2 – More questions (Internal Nodes)**: Is the applicant&#39;s income &gt; $50,000?\n  - If yes, approve the loan (Leaf Node).\n  - If no, go to Leaf Node (Do not approve the loan).\n- **Step 3 - Decision (Leaf Node)**\n  - Leaf Node 1: Do not approve the loan (if credit score ≤ 700).\n  - Leaf Node 2: Approve the loan (if credit score &gt; 700 and income &gt; $50,000).\n  - Leaf Node 3: Do not approve the loan (if credit score &gt; 700 and income ≤ $50,000).\n\n**Common pitfall:** Trees tend to overfit the data if you allow it to go too deep and include too many branches. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-does-a-random-forest-differ-from-a-decision-tree&quot;],&quot;question&quot;:[0,&quot;How does a random forest differ from a decision tree?&quot;],&quot;answer&quot;:[0,&quot;This table describes the difference between decision trees and random forests and when to use them based on features like accuracy, training time, etc.\n\n![Decision tree vs random forest](https://assets.roadmap.sh/guest/random-forest-vs-decision-tree-e8js9.png)\n\nA random forest is a collection of multiple decision trees, while a decision tree is just a single model that predicts outcomes based on a series of decisions. For a random forest, each tree is trained on a subset of the data and a subset of features, and both of these are random. A decision tree is a simple, tree-like structure used to represent decisions and the possible outcomes from them. Random forest multiple trees use bootstrapped samples and random feature selection, then average predictions to improve accuracy and reduce overfitting. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-does-logistic-regression-work&quot;],&quot;question&quot;:[0,&quot;How does logistic regression work?&quot;],&quot;answer&quot;:[0,&quot;Logistic regression is a supervised machine learning algorithm commonly used for binary classification tasks by predicting the probability of an outcome, event, or observation. The model delivers a binary outcome limited to two possible outcomes: yes/no, 0/1, or true/false. Logical regression analyzes the relationship between one or more independent variables and classifies the data into discrete classes. This relationship is then used to predict the value of one of those factors, the probability of a binary outcome using the logistic (sigmoid) function. It is mostly used for predictive modeling.\n\nFor example, 0 represents a negative class, and 1 represents a positive class. Logistic regression is commonly used in binary classification problems where the outcome variable reveals either of the two categories (0 and 1).\n\n**Common pitfall:** Misunderstanding that logistic regression is not a classification algorithm but a probability estimator. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-linear-regression-and-what-are-the-different-assumptions-of-linear-regression-algorithms&quot;],&quot;question&quot;:[0,&quot;What is linear regression, and what are the different assumptions of linear regression algorithms?&quot;],&quot;answer&quot;:[0,&quot;Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It is a type of supervised machine learning algorithm that computes the linear relationship between the dependent variable and one or more independent features by fitting a linear equation with observed data. It predicts the output variables based on the independent input variable.\n\nFor example, if you want to predict someone&#39;s salary, you use various factors such as years of experience, education level, industry of employment, and location of the job. Linear regression uses all these parameters to predict the salary as it is considered a linear relation between all these factors and the price of the house.\n\n**Assumptions for linear regression include:**\n\n- **Linearity:** Linear regression assumes there is a linear relationship between the independent and dependent variables. This means that changes in the independent variable lead to proportional changes in the dependent variable, whether positively or negatively.\n- **Independence of errors:** The observations should be independent from each other, that is, the errors from one observation should not influence another.\n- **Homoscedasticity (equal variance):** Linear regression assumes the variance of the errors is constant across all levels of the independent variable(s). This indicates that the amount of the independent variable(s) has no impact on the variance of the errors.\n- **Normality of residuals:** This means that the residuals should follow a bell-shaped curve. If the residuals are not normally distributed, then linear regression will not be an accurate model.\n- **No multicollinearity:** Linear regression assumes there is no correlation between the independent variables chosen for the model. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-are-support-vectors-in-svm-(support-vector-machine)&quot;],&quot;question&quot;:[0,&quot;What are support vectors in SVM (Support Vector Machine)?&quot;],&quot;answer&quot;:[0,&quot;A Support Vector Machine (SVM) is a supervised machine learning algorithm used mainly for classification tasks. It finds the optimal hyperplane in an N-dimensional space that separates data points into different classes while maximizing the margin between the closest points of each class.\n\nSupport vectors are the most important data points, useful in defining the optimal hyperplane that separates different classes. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-knn-and-k-means&quot;],&quot;question&quot;:[0,&quot;What is the difference between KNN and K-means?&quot;],&quot;answer&quot;:[0,&quot;KNN stands for K-nearest neighbors is a classification (or regression) algorithm that, to determine the classification of a point, combines the classification of the K nearest points. It is **supervised** because you are trying to classify a point based on the known classification of other points.\n\n**K-means** is a clustering algorithm that tries to partition a set of points into K sets (clusters) such that the points in each cluster tend to be near each other. It is **unsupervised** because the points have no external classification.\n\n![KNN vs. K-means](https://assets.roadmap.sh/guest/knn-vs-k-means-iqkbo.png)\n\nThis table shows the difference between KNN and K-means depending on the use case, data usage, purpose, and other features.\n\n| **Feature**          | **K-Nearest Neighbors (KNN)**                                              | **K-Means Clustering**                                              |\n| -------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------------- |\n| **Algorithm Type**   | Supervised Learning (Classification/Regression)                            | Unsupervised Learning (Clustering)                                  |\n| **Purpose**          | Classifies new data points on labeled training data                        | Groups unlabeled data points into clusters                          |\n| **Data Usage**       | Uses the entire dataset for predictions                                    | Splits the data into clusters iteratively                           |\n| **Scalability**      | Slow for large datasets because all data points are needed for predictions | Faster for large datasets because initial centroids are already set |\n| **Example Use Case** | Image Classification, Recommendation Systems                               | Customer Grouping                                                   | &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what&#39;s-the-difference-between-bagging-and-boosting&quot;],&quot;question&quot;:[0,&quot;What&#39;s the difference between bagging and boosting?&quot;],&quot;answer&quot;:[0,&quot;Ensemble techniques in machine learning combine multiple weak models into a strong, more accurate predictive model, using the collective intelligence of diverse models to improve performance. Bagging and boosting are different ensemble techniques that use multiple models to reduce error and optimize the model.\n\n![Bagging vs. boosting](https://assets.roadmap.sh/guest/difference-between-bagging-and-boosting-4j47l.png)\n\nThe bagging technique uses multiple models trained on different subsets of data. It decreases the variance and helps to avoid overfitting. It is usually applied to decision tree methods and is a special case of the model averaging approach. Boosting is an ensemble modeling technique designed to create a strong classifier by combining multiple weak classifiers. The process involves building models sequentially, where each new model aims to correct the errors made by the previous ones.\n\n- **Bagging:** Builds multiple models in parallel using bootstrapped datasets to reduce variance (e.g., Random Forest).\n- **Boosting:** Builds models sequentially, each trying to correct errors from the previous, reducing bias (e.g., XGBoost). &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;compare-and-contrast-linear-regression-and-logistic-regression.-when-would-you-use-one-over-the-other&quot;],&quot;question&quot;:[0,&quot;Compare and contrast linear regression and logistic regression. When would you use one over the other?&quot;],&quot;answer&quot;:[0,&quot;A linear regression algorithm defines a linear relationship between independent and dependent variables. It uses a linear equation to identify the line of best fit (straight line) for a problem, which it then uses to predict the output of the dependent variables.\n\n![Linear and logistic regression](https://assets.roadmap.sh/guest/what-is-linear-and-logistic-regression-ipjtz.png)\n\nA logistic regression algorithm predicts a binary outcome for an event based on a dataset&#39;s previous observations. Its output lies between 0 and 1. The algorithm uses independent variables to predict the occurrence or failure of specific events.\n\nYou use linear regression when the outcome is a continuous value, such as price or temperature. You should use logistic regression when the outcome is a categorical value like spam/not spam, yes/no, etc.\n\n![Linear vs. logistic regression](https://assets.roadmap.sh/guest/linear-vs-logistic-regression-a7cc3.png) &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-regularization-(l1-and-l2)-and-why-is-it-useful&quot;],&quot;question&quot;:[0,&quot;What is regularization (L1 and L2), and why is it useful?&quot;],&quot;answer&quot;:[0,&quot;Regularization is a technique in machine learning to prevent models from overfitting. Overfitting happens when a model doesn&#39;t just learn from the underlying patterns (signals) in the training data but also picks up and amplifies the noise in it. This leads to a model that performs well on training data but poorly on new data.\n\nL1 and L2 regularization are methods used to mitigate overfitting in machine learning models by adding a penalty term on coefficients to the model&#39;s loss function. This penalty discourages the model from assigning too much importance to any single feature (represented by large coefficients), making the model more straightforward. Regularization keeps the model balanced and focused on the true signal, enhancing its ability to generalize to unseen data.\n\nA regression model that uses the L1 regularization technique is called lasso regression, and a model that uses the L2 is called ridge regression.\n\n- **L1 Regularization:** Also called a lasso regression, this adds the absolute value of the sum (\&quot;absolute value of magnitude\&quot;) of coefficients as a penalty term to the loss function.\n- **L2 Regularization:** Also called a ridge regression, this adds the squared sum (\&quot;squared magnitude\&quot;) of coefficients as the penalty term to the loss function. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-are-precision-recall-f1-score-and-auc-roc&quot;],&quot;question&quot;:[0,&quot;What are precision, recall, F1 score, and AUC-ROC?&quot;],&quot;answer&quot;:[0,&quot;Once a machine learning model has been created, it is important to evaluate and test how well it performs on data. An evaluation metric is a mathematical quantifier of the quality of the model. Precision, Recall, F1 Score, and AUC-ROC are all evaluation metrics.\n\n- **Precision** is all about how accurate your positive predictions are. Of all the items your model labeled as positive, how many were actually positive?\n  **Formula = TP / (TP + FP).** It tells you how much you can trust the positives your model finds.\n- **Recall** focuses on finding all the actual positives. It measures how well your model catches everything it should&#39;ve caught.\n  **Formula = TP / (TP + FN).** It&#39;s especially useful when missing a positive is costly like missing a cancer diagnosis.\n- **F1 Score:** F1 Score combines Recall and Precision into one performance metric. The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. F1 is usually more useful than Accuracy, especially if you have an uneven class distribution.\n- **AUC-ROC:** The AUC-ROC curve is a tool for evaluating the performance of binary classification models. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at different thresholds, showing how well a model can distinguish between two classes, such as positive and negative outcomes. It provides a graphical representation of the model&#39;s ability to distinguish between two classes, like a positive class for the presence of a disease and a negative class for the absence of a disease.\n\n**Key:** TP = True Positive, FP = False Positive, FN = False Negative. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-a-confusion-matrix-and-how-do-you-interpret-it&quot;],&quot;question&quot;:[0,&quot;What is a confusion matrix, and how do you interpret it?&quot;],&quot;answer&quot;:[0,&quot;A confusion matrix is a simple table that shows how well a classification model is performing by comparing its predictions to the actual results. It breaks down the predictions into four categories: correct predictions for both classes (true positives and true negatives) and incorrect predictions (false positives and false negatives). This helps you understand where the model is making mistakes so you can improve it.\n\n- **TP:** True Positives\n- **TN:** True Negatives\n- **FP:** False Positives\n- **FN:** False Negatives\n\n![Confusion matrix](https://assets.roadmap.sh/guest/actual-values-qnezf.png)\n\n**Example:** From the matrix below, there are 165 total cases:\n\n- **True Negatives:** **50**\n- **False Positives:** **10**\n- **False Negatives:** **5**\n- **True Positives:** **100**\n\nDepending on the project you&#39;re working on, you can use metrics such as Accuracy, Precision, Recall, and F1 Score to evaluate your project. A confusion matrix is a visualization of it.\n\n![An example of confusion matrix](https://assets.roadmap.sh/guest/sample-confusion-matrix-l4q8i.png)\n\n**Common pitfall:** Misreading the matrix layout or assuming it works for multi-class without modification. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-feature-selection-methods-do-you-prefer-when-building-a-predictive-model-how-do-you-determine-which-features-to-keep-or-discard&quot;],&quot;question&quot;:[0,&quot;What feature selection methods do you prefer when building a predictive model? How do you determine which features to keep or discard?&quot;],&quot;answer&quot;:[0,&quot;When building a predictive model, I like to combine practical steps and proven techniques to ensure that the features I include actually help the model rather than add noise, redundancy, or overfitting risk.\n\n**I&#39;ll approach like this:**\n\n1. **Start with domain knowledge:** Talk to stakeholders and review documentation to understand what features make the most sense in our business context.\n2. **Use filter methods for a first pass:** I run statistical checks like correlation, ANOVA, chi-square tests, or mutual information to remove irrelevant or redundant features. Filter methods are fast, which is especially helpful when you&#39;re working with high-dimensional data.\n3. **Apply wrapper methods for performance tuning:** For a more refined selection, I use wrapper methods like Recursive Feature Elimination (RFE). These methods evaluate subsets of features based on how well the model performs, which helps surface the most predictive combinations. They take more time but are worth it for high-impact models.\n4. **Leverage embedded methods for efficiency:** Models like Lasso (L1), Ridge (L2), and tree-based models (Random Forest, XGBoost) have built-in feature importance. I like these because they optimize feature selection during model training, balancing speed and accuracy.\n5. **Hybrid approach:** Sometimes, I start with a filter method to reduce dimensions and then fine-tune with wrapper or embedded methods. This hybrid approach saves time and improves performance.\n\n**How I decide what to drop or keep:**\n\n- If a feature is highly correlated with another, I drop the weaker or noisier one.\n- If it has low variance and no predictive power, it goes.\n- If it helps interpretability or improves metrics on validation data, I keep it.\n- If it harms generalization or adds complexity, I drop it. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;explain-the-difference-between-false-positive-and-false-negative-rates-in-a-confusion-matrix.-how-do-these-metrics-impact-model-evaluation-in-a-fraud-detection-scenario&quot;],&quot;question&quot;:[0,&quot;Explain the difference between false positive and false negative rates in a confusion matrix. How do these metrics impact model evaluation in a fraud detection scenario?&quot;],&quot;answer&quot;:[0,&quot;False Positive Rate (FPR) is the proportion of actual negatives that are incorrectly identified to be true. False Negative Rate is the proportion of actual positives that are incorrectly identified as negatives.\n\nIn a fraud detection scenario, both of these have damaging consequences:\n\n**False Positive Rate (FPR)**: If a model has a high false positive rate, it means the system flags many legitimate transactions as fraudulent. This will lead to customer frustration, as their transactions will be flagged regularly, and they could leave.\n\n**False Negative Rate (FNR)**: If a model has a high false negative rate, it means many fraudulent transactions are not detected, which could lead to significant financial business loss. &quot;],&quot;topics&quot;:[1,[[0,&quot;Machine Learning and Algorithms&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;write-an-sql-query-to-get-the-second-highest-salary-from-an-employee-table.&quot;],&quot;question&quot;:[0,&quot;Write an SQL query to get the second-highest salary from an employee table.&quot;],&quot;answer&quot;:[0,&quot;To find the second highest salary, you can take one of two common methods: a subquery or a window function.\n\n**Method 1: Subquery method**\nYou first get the maximum salary from the table. Then, you find the highest salary that&#39;s less than that max, giving you the second highest salary.\n\nThis method is clean and efficient:\n\n```sql\nSELECT MAX(salary) AS SecondHighest\nFROM employee\nWHERE salary &lt; (SELECT MAX(salary) FROM employee);\n```\n\n**Method 2: Window function with DENSE_RANK()**\nYou rank all salaries in descending order using DENSE_RANK(), then filter for rank 2 to get the second highest. The LIMIT 1 ensures only one row is returned in case of ties. This method is better for flexibility if you want to choose the third highest or fourth, etc.\n\n```sql\nSELECT salary AS SecondHighest\nFROM (\n  SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rank\n  FROM employee\n) ranked\nWHERE rank = 2\nLIMIT 1;\n```\n&quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;joining-orders-with-customer-information&quot;],&quot;question&quot;:[0,&quot;Joining orders with customer information&quot;],&quot;answer&quot;:[0,&quot;To join order details with corresponding customer information, you use a simple inner join:\n\n```sql\nSELECT o.*, c.name, c.email\nFROM orders o\nJOIN customers c ON o.customer_id = c.id;\n```\n\nThis pulls all orders where a matching customer exists. If you need **every order**, even those without matching customers, switch to a LEFT JOIN:\n\n```sql\nSELECT o.*, c.name, c.email\nFROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id;\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;write-an-sql-query-to-find-the-top-5-customers-by-revenue.&quot;],&quot;question&quot;:[0,&quot;Write an SQL query to find the top 5 customers by revenue.&quot;],&quot;answer&quot;:[0,&quot;To get the highest-spending customers, group by customer, sum their order totals, sort by that total, and limit the results:\n\n```sql\nSELECT customer_id, SUM(total_amount) AS revenue\nFROM orders\nGROUP BY customer_id\nORDER BY revenue DESC\nLIMIT 5;\n```\n\nTo add customer names, just join with the customers&#39; table.\n\n**Common pitfall:** Not grouping properly before ordering can result in incorrect aggregates. &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;write-an-sql-query-to-find-the-top-five-customers-by-purchase-amount-in-the-last-quarter.&quot;],&quot;question&quot;:[0,&quot;Write an SQL query to find the top five customers by purchase amount in the last quarter.&quot;],&quot;answer&quot;:[0,&quot;To find your top customers *who also bought across multiple categories*, filter purchases within 3 months, group by customer, and apply category constraints with HAVING:\n\n```sql\nSELECT customer_id, SUM(amount) AS total_spent\nFROM purchases\nWHERE purchase_date &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)\nGROUP BY customer_id\nHAVING COUNT(DISTINCT category_id) &gt;= 3\nORDER BY total_spent DESC\nLIMIT 5;\n```\n\nThis makes sure each customer bought from **at least 3 categories**. WHERE filters rows **before** grouping, while HAVING filters groups **after**. &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-remove-duplicates-from-a-dataframe&quot;],&quot;question&quot;:[0,&quot;How do you remove duplicates from a DataFrame?&quot;],&quot;answer&quot;:[0,&quot;To remove duplicates from a DataFrame:\n```python\ndf = df.drop_duplicates()\n```\nYou can also refine this by specifying columns:\n\n```python\n# Drop duplicates based on specific columns\ndf = df.drop_duplicates(subset=[&#39;customer_id&#39;, &#39;product_id&#39;])\n```\n\nControl which duplicates to keep:\n\n```python\n# Keep first or last occurrence\ndf = df.drop_duplicates(keep=&#39;last&#39;)  # or &#39;first&#39;\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;given-a-stream-of-data-how-would-you-find-the-median-in-real-time&quot;],&quot;question&quot;:[0,&quot;Given a stream of data, how would you find the median in real time?&quot;],&quot;answer&quot;:[0,&quot;To compute the median in a stream of numbers, use two heaps:\n\n- Max-heap for the lower half\n- Min-heap for the upper half\n- Keep both heaps balanced\n- The median is either the top of one heap or the average of both tops\n\n```python\nimport heapq\n\nclass MedianFinder:\n    def __init__(self):\n        self.small = []  # max heap (negative values)\n        self.large = []  # min heap\n    \n    def add_num(self, num):\n        if len(self.small) == len(self.large):\n            heapq.heappush(self.large, -heapq.heappushpop(self.small, -num))\n        else:\n            heapq.heappush(self.small, -heapq.heappushpop(self.large, num))\n    \n    def find_median(self):\n        if len(self.small) == len(self.large):\n            return (self.large[0] - self.small[0]) / 2.0\n        else:\n            return self.large[0]\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;merge-overlapping-intervals&quot;],&quot;question&quot;:[0,&quot;Merge overlapping intervals&quot;],&quot;answer&quot;:[0,&quot;To merge overlapping intervals, first sort them, then iterate and merge as needed:\n\n```python\ndef merge_intervals(intervals):\n    intervals.sort(key=lambda x: x[0])\n    merged = [intervals[0]]\n    for current in intervals[1:]:\n        last = merged[-1]\n        if current[0] &lt;= last[1]:\n            last[1] = max(last[1], current[1])\n        else:\n            merged.append(current)\n    return merged\n```\n\nSorting takes O(n log n), and the merge step is linear, making this efficient for large datasets. &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-handle-null-values-in-pandas&quot;],&quot;question&quot;:[0,&quot;How do you handle null values in pandas?&quot;],&quot;answer&quot;:[0,&quot;Basic null handling options:\n\n```python\ndf.fillna(0)      # Replace with 0  \ndf.dropna()       # Drop rows with nulls\n```\n\nOther methods to consider:\n\n```python\n# Fill with mean/median/mode\ndf[&#39;column&#39;].fillna(df[&#39;column&#39;].mean())\ndf[&#39;column&#39;].fillna(df[&#39;column&#39;].median())\ndf[&#39;column&#39;].fillna(df[&#39;column&#39;].mode()[0])\n\n# Forward/backward fill\ndf.fillna(method=&#39;ffill&#39;)  # Use previous value\ndf.fillna(method=&#39;bfill&#39;)  # Use next value\n\n# Interpolation\ndf.interpolate()\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-group-and-aggregate-data-in-python&quot;],&quot;question&quot;:[0,&quot;How would you group and aggregate data in Python?&quot;],&quot;answer&quot;:[0,&quot;Basic group and sum:\n\n```python\ndf.groupby(&#39;category&#39;)[&#39;sales&#39;].sum()\n```\n\nFor more complex aggregations:\n\n```python\n# Multiple aggregations\ndf.groupby(&#39;category&#39;).agg({\n    &#39;sales&#39;: [&#39;sum&#39;, &#39;mean&#39;, &#39;count&#39;],\n    &#39;profit&#39;: [&#39;min&#39;, &#39;max&#39;]\n})\n\n# Custom aggregation functions\ndf.groupby(&#39;category&#39;)[&#39;sales&#39;].agg(lambda x: x.max() - x.min())\n\n# Reset index to convert back to a regular DataFrame\ndf.groupby(&#39;category&#39;)[&#39;sales&#39;].sum().reset_index()\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;why-does-rank()-skip-sequence-numbers-in-sql&quot;],&quot;question&quot;:[0,&quot;Why does RANK() skip sequence numbers in SQL?&quot;],&quot;answer&quot;:[0,&quot;```\nGiven values: 100, 90, 90, 80\nRANK(): Skips ranks after ties\n→ 1, 2, 2, 4\nDENSE_RANK(): No skipping\n→ 1, 2, 2, 3\nROW_NUMBER(): Ignores ties\n→ 1, 2, 3, 4\n```&quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;why-use-a-right-join-when-a-left-join-can-suffice&quot;],&quot;question&quot;:[0,&quot;Why use a RIGHT JOIN when a LEFT JOIN can suffice?&quot;],&quot;answer&quot;:[0,&quot;A RIGHT JOIN is the same as a LEFT JOIN with the table order reversed:\n\n```sql\nSELECT * FROM A RIGHT JOIN B ON A.id = B.id;\nSELECT * FROM B LEFT JOIN A ON A.id = B.id;\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what&#39;s-the-difference-between-.apply()-and-.map()-in-pandas&quot;],&quot;question&quot;:[0,&quot;What&#39;s the difference between .apply() and .map() in pandas?&quot;],&quot;answer&quot;:[0,&quot;- .map(): Works only on Series, applies a function element-wise\n- .apply(): More versatile, works on both Series and DataFrames\n- .applymap(): Applies a function to every element in a DataFrame\n\n```python\n# map - simple transformation of Series values\ndf[&#39;category&#39;] = df[&#39;category_id&#39;].map({1: &#39;Electronics&#39;, 2: &#39;Clothing&#39;})\n\n# apply on Series - more complex operations\ndf[&#39;name&#39;] = df[&#39;name&#39;].apply(lambda x: x.title())\n\n# apply on DataFrame - process entire rows or columns\ndf.apply(lambda x: x.max() - x.min())\n\n# applymap - element-wise operation on entire DataFrame\ndf.applymap(lambda x: f\&quot;{x:.2f}\&quot; if isinstance(x, float) else x)\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-implement-k-means-clustering-in-python&quot;],&quot;question&quot;:[0,&quot;How would you implement K-Means clustering in Python?&quot;],&quot;answer&quot;:[0,&quot;**Basic usage:**\n\n```python\nfrom sklearn.cluster import KMeans  \nkmeans = KMeans(n_clusters=3).fit(X)\nlabels = kmeans.labels_\n```\n\n**Best practices for K-Means:**\n\n```python\n# Scale features\nfrom sklearn.preprocessing import StandardScaler\nX_scaled = StandardScaler().fit_transform(X)\n\n# Use elbow method to find optimal k\ndistortions = []\nK_range = range(1, 10)\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_scaled)\n    distortions.append(kmeans.inertia_)\n\n# Plot elbow curve\nimport matplotlib.pyplot as plt\nplt.plot(K_range, distortions)\nplt.xlabel(&#39;k&#39;)\nplt.ylabel(&#39;Distortion&#39;)\nplt.title(&#39;Elbow Method For Optimal k&#39;)\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-find-rmse-and-mse-in-a-linear-regression-model&quot;],&quot;question&quot;:[0,&quot;How do you find RMSE and MSE in a linear regression model?&quot;],&quot;answer&quot;:[0,&quot;**To evaluate a regression model:**\n\n```python\nfrom sklearn.metrics import mean_squared_error  \nimport numpy as np  \nmse = mean_squared_error(y_true, y_pred)  \nrmse = np.sqrt(mse)\n```\n\n- **MSE:** Penalizes large errors heavily.\n- **RMSE:** More interpretable because it&#39;s in the same unit as the target.\n\n**Another alternative:**\n\n```python\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(y_true, y_pred)\n```\n\n**MAE** is less sensitive to outliers. &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-can-you-calculate-accuracy-using-a-confusion-matrix&quot;],&quot;question&quot;:[0,&quot;How can you calculate accuracy using a confusion matrix?&quot;],&quot;answer&quot;:[0,&quot;```python\naccuracy = (TP + TN) / (TP + TN + FP + FN)\nprecision = TP / (TP + FP)  # How many selected items are relevant\nrecall = TP / (TP + FN)     # How many relevant items are selected\nf1_score = 2 * (precision * recall) / (precision + recall)  # Harmonic mean\n\n# For imbalanced datasets, consider:\nspecificity = TN / (TN + FP)\nbalanced_accuracy = (recall + specificity) / 2\n``` &quot;],&quot;topics&quot;:[1,[[0,&quot;Coding Challenges&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-measure-the-success-of-a-new-product-launch&quot;],&quot;question&quot;:[0,&quot;How would you measure the success of a new product launch?&quot;],&quot;answer&quot;:[0,&quot;First, define success for that specific launch. Is it getting 1,000 new users in 30 days? Hitting a revenue or CTR goal? Building awareness in a new market? Or collecting feedback for future improvements?\n\nOnce that&#39;s clear, measure success using a mix of quantitative and qualitative KPIs across teams like marketing, product, and customer success. Some metrics I&#39;ll look at:\n\n- **Launch campaign metrics:** To gauge marketing performance, look at leads generated, channel performance (email, ads, social), website traffic, and press coverage.\n- **Product adoption metrics:** After launch, track trials, usage, activation, and user retention. These show how well the product is landing with your target audience.\n- **Market impact metrics:** Measure business impact through revenue, market share, and win rates against competitors.\n- **Qualitative feedback:** Talk to sales reps, product teams, and customers. Internal and external feedback helps you understand the \&quot;why\&quot; behind the numbers. Blending data with direct feedback gives you a more transparent, more nuanced view of what&#39;s working and what to improve.\n\n**Common pitfall:** Focusing only on quantitative metrics without applying nuance to them. An example is tracking metrics like downloads without tracking engagement. Or tracking views without knowing who is viewing them. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;you-notice-a-sudden-drop-in-website-traffic-how-would-you-investigate-it&quot;],&quot;question&quot;:[0,&quot;You notice a sudden drop in website traffic, how would you investigate it?&quot;],&quot;answer&quot;:[0,&quot;To analyze a sudden drop in website traffic, I would follow these steps:\n\n- **Determine if it&#39;s a drop or a trend:** The first thing to do is try to understand whether your traffic has been declining for a while or if it has suddenly dropped for a day or two.  \n- **Rule out any manual actions:** Sometimes, traffic drops happen because of a Google penalty. Check to see if there are any recent changes that you might have fallen foul of. Also, make sure that updates you made to your website&#39;s content didn&#39;t cause a problem. \n- **Check for algorithm updates:** Google frequently updates its ranking algorithm. When your site&#39;s performance drops suddenly, it&#39;s worth investigating whether an update might be responsible.\n- **Investigate technical issues:** Some of the most common technical issues are indexing errors, site speed, performance, and mobile usability.\n- **Check competitor activity:** Sometimes, traffic dips occur because competitors have stepped up their game. SEO tools like Ahrefs, SEMrush, or Moz help track your competitors&#39; backlinks, keywords, and rankings. Check to see whether your competitors have started outranking you for previously held keywords or launched new content targeting your primary audience. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-if-a-model-is-95percent-accurate-but-the-business-is-unhappy-with-the-results&quot;],&quot;question&quot;:[0,&quot;What if a model is 95% accurate, but the business is unhappy with the results?&quot;],&quot;answer&quot;:[0,&quot;There could be multiple reasons why a business could be unsatisfied with a model that has high accuracy. Some reasons are:\n\n- **Focusing on the wrong metric:** Sometimes, a model is not optimized for the specific business problem. Its accuracy is tied to the wrong thing. For example, in fraud detection, it is possible to still miss fraudulent transactions even with high accuracy scores.\n- **Unrealistic expectations:** The model might have unrealistic expectations placed on it to solve problems when, in reality, it is meant to be used in conjunction with other methods and metrics to give a nuanced view.\n- **Overfitting:** It is possible that the high accuracy comes from the model learning the training data rather than learning how to generalize.\n\n**To handle this problem, I&#39;ll:**\n\n- **Reevaluate the business goals:** Sometimes, the business goals need to be defined so that there is a specific metric or group of metrics for the model to be trained towards.\n- **Improve the model performance:** You should do a deep dive into the model and fix any issues that you might notice, including overfitting, data issues or feature selection. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;you&#39;re-given-a-random-dataset-how-do-you-check-if-it&#39;s-useful&quot;],&quot;question&quot;:[0,&quot;You&#39;re given a random dataset, how do you check if it&#39;s useful?&quot;],&quot;answer&quot;:[0,&quot;To check the quality of a random dataset, I&#39;ll:\n\n- **Understand the problem context:** The first thing to do is to make sure you understand the goal you aim to achieve before looking at the dataset. This allows you to know from first glance whether the dataset matches the problem. If the data has irrelevant columns, you should remove them.\n\n- **Test the data quality:** For any problem you are solving, it has most likely been solved before. You can test your dataset against a trusted dataset to measure any deviations that might be in the data. The dataset also needs to represent real-world scenarios.\n\n- **Technical checks:** With technical checks, it&#39;s good to remove duplicates in the data. Noise could be present with blurry images or mislabeled samples. You also have to make sure everything is formatted correctly in a consistent format.\n\n- **Assess practical utility:** The dataset has to be big enough for what you need it to do. For traditional machine learning, the dataset should be more than 10 times greater than the number of features per class. For deep learning, you should aim for 100 features per class to help avoid overfitting.\n\nA dataset is only useful when it aligns with the problem&#39;s context and goals. It must pass accuracy, completeness, and balance checks. Finally, it must meet size and representative requirements. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-evaluate-a-classification-model-for-medical-diagnosis&quot;],&quot;question&quot;:[0,&quot;How would you evaluate a classification model for medical diagnosis?&quot;],&quot;answer&quot;:[0,&quot;Healthcare classification models use machine learning to analyze vast amounts of patient data. They identify complex patterns and relationships, helping healthcare professionals predict health risks more accurately. These models help doctors make the right decision and reduce diagnostic errors. To evaluate classification models, you have to know the right metrics to use.\n\n- **Accuracy, sensitivity, and specificity metrics**: Accuracy, sensitivity, and specificity are critical in evaluating medical models. Accuracy measures the overall correctness of predictions. Sensitivity, or recall, shows the model&#39;s ability to identify positive cases. Specificity indicates how well it identifies negative cases. These metrics are vital for diagnostic accuracy assessment in various medical fields.\n- **ROC curves and AUC analysis**: ROC curves and AUC analysis are key metrics for healthcare AI performance. They evaluate a model&#39;s ability to distinguish between classes at different thresholds. A higher AUC score means better performance in distinguishing between positive and negative cases.\n- **Cross-validation techniques**: Cross-validation estimates a model&#39;s performance on unseen data. Techniques like k-fold cross-validation split data into subsets for training and testing, providing a robust assessment of the model&#39;s ability to generalize. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-is-the-difference-between-batch-and-online-learning&quot;],&quot;question&quot;:[0,&quot;What is the difference between batch and online learning?&quot;],&quot;answer&quot;:[0,&quot;Batch learning is a term in artificial intelligence that refers to the process of training a machine learning model on a large set of data all at once, instead of continuously updating the model as new data comes in. This method allows for greater consistency and efficiency in the training process, as the model can learn from a fixed set of data before being deployed for use.\n\nIn batch learning, the model sees the entire dataset multiple times (known as epochs), refining its understanding with each pass. By processing data in large chunks, it converges more slowly but generally achieves higher accuracy.\n\nOnline learning takes a continuous, incremental approach. Instead of waiting for all the data to be available, you feed it to the model bit by bit, just like learning something new every day instead of cramming for a final exam. The model updates with each new data point, so it&#39;s constantly learning and evolving.\n\nFor example, imagine you&#39;re monitoring customer behavior on a website. Every time a user clicks or makes a purchase, your model gets smarter, learning from that single interaction and refining its predictions for the next. &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;what-are-the-pros-and-cons-of-deep-learning-vs.-traditional-ml&quot;],&quot;question&quot;:[0,&quot;What are the pros and cons of deep learning vs. traditional ML?&quot;],&quot;answer&quot;:[0,&quot;**Deep learning** uses multi-layered neural networks to handle complex tasks like image recognition, NLP, and recommendation systems. Think CNNs, RNNs, and Transformers.\n\n**Pros:**\n\n- Handles complex, high-dimensional data (images, audio, text)\n- Works with both structured and unstructured data\n- Learns non-linear relationships\n- Scales well across use cases with techniques like transfer learning\n- Great at generalizing from large datasets\n\n**Cons:**\n\n- Requires lots of data and compute\n- Heavily dependent on data quality\n- Hard to interpret (black box)\n- Comes with privacy and security concerns\n\nTraditional ML uses simpler, more interpretable algorithms like decision trees, logistic regression, and support vector machines.\n\n**Pros:**\n\n- Works well with smaller datasets\n- Faster to train and more straightforward to interpret\n- Lower computational cost\n- More transparent and explainable\n\n**Cons:**\n\n- Struggles with complex/non-linear data\n- Needs manual feature engineering\n- Doesn&#39;t scale well with large datasets\n- Can overfit if not tuned properly &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-monitor-model-performance-in-production&quot;],&quot;question&quot;:[0,&quot;How do you monitor model performance in production?&quot;],&quot;answer&quot;:[0,&quot;You monitor model performance in production by tracking both functional and operational metrics.\n\n**Functional monitoring** checks the health of the data and the model:\n\n- **Data quality**: Monitor for missing values, duplicates, and syntax errors.\n- **Data/feature drift**: Compare current input data to training data using stats like KL divergence, PSI, chi-squared, etc.\n- **Model drift**: Check if model accuracy drops over time due to changing patterns in the data.\n\n**Operational monitoring** keeps the system running smoothly:\n\n- **System health**: Tracks latency, errors, and memory usage.\n- **Input data health**: Watch for type mismatches, nulls, and out-of-range values.\n- **Model performance**: Use precision/recall, RMSE, or top-k accuracy depending on the use case.\n- **Business KPIs**: Tie model performance to actual business outcomes (e.g., conversions, revenue impact). &quot;],&quot;topics&quot;:[1,[[0,&quot;Real Business Scenarios&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-would-you-detect-concept-drift-in-your-model&quot;],&quot;question&quot;:[0,&quot;How would you detect concept drift in your model?&quot;],&quot;answer&quot;:[0,&quot;Concept drift happens when the relationship between your input features and target variable changes over time, causing your model&#39;s performance to drop. It&#39;s common in dynamic environments (e.g., user behavior, market trends). COVID-19 is a real-world example: models trained pre-pandemic broke down because behavior and data patterns shifted.\n\n**How to detect it:**\n\n- **Set up reference vs. detection windows:** Compare a stable past dataset (e.g., January traffic) against a current window (e.g., this week). This gives you a baseline.\n- **Compare distributions:** Use statistical tests (e.g., Kolmogorov–Smirnov, PSI, KL divergence) to detect shifts in data or feature distributions.\n- **Track model performance over time:** Drop in precision, recall, or overall accuracy compared to your baseline = red flag.\n- **Run significance tests:** This tells you if the drift is real or just noise. &quot;],&quot;topics&quot;:[1,[[0,&quot;Advanced Topics&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;how-do-you-ensure-fairness-and-remove-bias-from-your-models&quot;],&quot;question&quot;:[0,&quot;How do you ensure fairness and remove bias from your models?&quot;],&quot;answer&quot;:[0,&quot;Fairness means your model makes decisions that don&#39;t unfairly favor or penalize any group. Bias can sneak in at any stage, like data collection, labeling, training, and even deployment, so it needs to be addressed early and often.\n\n**How to ensure fairness:**\n\n- **Start with diverse training data:** Your data should reflect all the groups your model impacts. If it&#39;s skewed, the model will be too.\n- **Preprocess to balance representation:** Use techniques like oversampling underrepresented groups or reweighting the data.\n- **Use bias detection tools:** Libraries like Fairlearn, AIF360, and What-If Tool can help you spot performance gaps across subgroups.\n- **Apply fairness constraints during training:** Use regularization, adversarial debiasing, or post-processing adjustments to reduce harm to specific groups.\n- **Build transparency into the model:** Use interpretable models (e.g., decision trees, linear models) or explanation tools like SHAP and LIME.\n- **Audit regularly across subgroups:** Don&#39;t rely only on overall accuracy—look at performance across gender, race, age, etc.\n- **Bring in human oversight:** Humans should always be part of the loop, especially in high-stakes decisions (e.g., lending, hiring). &quot;],&quot;topics&quot;:[1,[[0,&quot;Advanced Topics&quot;]]],&quot;isLongAnswer&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;which-is-better-specializing-a-model-with-fine-tuning-or-generalizing-it-with-more-data&quot;],&quot;question&quot;:[0,&quot;Which is better - specializing a model with fine-tuning or generalizing it with more data?&quot;],&quot;answer&quot;:[0,&quot;Fine-tuning a model is the process of adapting a pre-trained model for specific tasks or use cases. The reasoning behind fine-tuning is that it is easier and cheaper to improve the capabilities of a pre-trained base model that has already learned road knowledge about the task than it is to train a new model from scratch.\n\nGeneralization is a measure of how your model performs in predicting unseen data. Generalizing with more data is improving the model&#39;s ability to make predictions on new data rather than the data it was trained on.\n\nChoosing whether to generalize with more data or fine-tune to achieve your goal depends on the specific situation.\n\n**For specialization with fine-tuning:**\n\n- It is better when high performance is needed on a very specific task or domain.\n- It is more efficient to use when you have limited resources, but good data for a specific task.\n- It can achieve strong results with smaller models.\n\n**For generalization with more data:**\n\n- It is better for models that need to handle a wide range of tasks.\n- It is great for situations where overfitting will be a problem. &quot;],&quot;topics&quot;:[1,[[0,&quot;Advanced Topics&quot;]]],&quot;isLongAnswer&quot;:[0,true]}]]]}" ssr client="load" opts="{&quot;name&quot;:&quot;QuestionsList&quot;,&quot;value&quot;:true}" await-children><div class="mb-0 gap-3 text-center sm:mb-40"><div class="mb-3 overflow-hidden rounded-lg border border-gray-300 bg-white p-4 sm:mb-5 sm:p-6"><div class="mb-3 flex items-center text-gray-600"><div class="relative w-full flex-1 rounded-xl bg-gray-200 p-1"><div class="absolute top-0 bottom-0 left-0 rounded-xl bg-slate-800 transition-[width] duration-400" style="width:0%"></div></div><span class="ml-3 flex items-center text-sm"><button class="text-zinc-400 hover:text-black"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-left h-4" aria-hidden="true"><path d="m15 18-6-6 6-6"></path></svg></button><span class="block min-w-[41px] text-center"><span class="tabular-nums">0</span> / <!-- -->63</span><button class="text-zinc-400 hover:text-black"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right h-4" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></button></span></div><div class="relative -left-1 flex flex-col gap-2 text-sm text-black sm:flex-row sm:gap-3"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-circle-check-big mr-1 h-4" aria-hidden="true"><path d="M21.801 10A10 10 0 1 1 17 3.335"></path><path d="m9 11 3 3L22 4"></path></svg><span>Knew</span><span class="ml-2 rounded-md bg-gray-200/80 px-1.5 font-medium text-black"><span class="tabular-nums">0</span> Items</span></span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sparkles mr-1 h-4" aria-hidden="true"><path d="M9.937 15.5A2 2 0 0 0 8.5 14.063l-6.135-1.582a.5.5 0 0 1 0-.962L8.5 9.936A2 2 0 0 0 9.937 8.5l1.582-6.135a.5.5 0 0 1 .963 0L14.063 8.5A2 2 0 0 0 15.5 9.937l6.135 1.581a.5.5 0 0 1 0 .964L15.5 14.063a2 2 0 0 0-1.437 1.437l-1.582 6.135a.5.5 0 0 1-.963 0z"></path><path d="M20 3v4"></path><path d="M22 5h-4"></path><path d="M4 17v2"></path><path d="M5 18H3"></path></svg><span>Learnt</span><span class="ml-2 rounded-md bg-gray-200/80 px-1.5 font-medium text-black"><span class="tabular-nums">0</span> Items</span></span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-skip-forward mr-1 h-4" aria-hidden="true"><polygon points="5 4 15 12 5 20 5 4"></polygon><line x1="19" x2="19" y1="5" y2="19"></line></svg><span>Skipped</span><span class="ml-2 rounded-md bg-gray-200/80 px-1.5 font-medium text-black"><span class="tabular-nums">0</span> Items</span></span><button class="flex items-center text-red-600 transition-opacity duration-300 hover:text-red-900 disabled:opacity-50"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-rotate-ccw mr-1 h-4" aria-hidden="true"><path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8"></path><path d="M3 3v5h5"></path></svg>Reset<span class="inline lg:hidden">Progress</span></button></div></div><div class="relative mb-4 flex min-h-[250px] w-full overflow-hidden rounded-lg border border-gray-300 bg-white sm:min-h-[400px]"><div class="flex grow flex-col items-center justify-center py-5 sm:py-8"><div class="hidden text-gray-400 sm:block"><span class="capitalize">Core Concepts</span></div><div class="mx-auto flex max-w-[550px] flex-1 items-center justify-center py-3 sm:py-8"><p class="px-4 text-xl font-semibold leading-snug! text-black sm:text-3xl">What is the difference between correlation and causation?</p></div><div class="text-center"><button class="cursor-pointer text-sm text-gray-500 underline underline-offset-4 transition-colors hover:text-black sm:text-base">Click to Reveal the Answer</button></div></div><div class="absolute left-0 right-0 flex flex-col items-center justify-center rounded-[7px] bg-neutral-100 py-4 text-sm leading-normal text-black transition-all duration-300 sm:py-8 sm:text-xl top-full"><div class="qa-answer prose prose-h5:font-semibold prose-h5:mb-2 prose-h5:text-black prose-sm prose-quoteless mx-auto flex w-full max-w-[600px] grow flex-col items-start justify-center py-0 px-4 text-left text-sm prose-h1:mb-2.5 prose-h1:mt-7 prose-h2:mb-3 prose-h2:mt-0 prose-h3:mb-[5px] prose-h3:mt-[10px] prose-p:mb-2 prose-p:mt-0 prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-gray-700 prose-pre:mb-6! prose-pre:w-full prose-ul:my-2 prose-li:m-0 prose-li:mb-0.5 sm:px-5 sm:text-lg sm:prose-p:mb-4"><p>Correlation is the statistical measure that shows a relationship between two variables. When one changes, the other changes as well, positively or negatively. However, this doesn't mean that one variable causes the other to change. Causation means that one variable directly causes a change in the other. It implies a cause-and-effect relationship, not just an association. Proving causation requires deeper analysis and additional evidence.</p>
<p><strong>Example:</strong> There's a correlation between cart abandonment and uninstall rates in a shopping app. Users who abandon their carts often end up uninstalling the app shortly after. But that doesn't mean abandoning a cart causes someone to uninstall the app. The real cause might be a frustrating purchase process with too many steps. That complexity leads to both behaviors: abandoning the cart and uninstalling the app. So, while there's a correlation, you can't say it's causation without looking deeper.</p>
<p><img src="https://assets.roadmap.sh/guest/difference-between-correlation-and-causation-j92us.png" alt="Correlation vs. causation"></p>
</div><div class="mt-7 text-center"><button class="cursor-pointer text-sm text-gray-500 underline underline-offset-4 transition-colors hover:text-black sm:text-base">Hide the Answer</button></div></div></div><div class="flex flex-col gap-1 transition-opacity duration-300 sm:flex-row sm:gap-3 opacity-100"><button class="flex flex-1 items-center rounded-md border border-gray-300 bg-white px-2 py-2 text-sm text-black transition-colors hover:border-black hover:bg-black hover:text-white disabled:pointer-events-none disabled:opacity-50 sm:rounded-lg sm:px-4 sm:py-3 sm:text-base"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-circle-check-big mr-1 h-4 text-current" aria-hidden="true"><path d="M21.801 10A10 10 0 1 1 17 3.335"></path><path d="m9 11 3 3L22 4"></path></svg>Already Know that</button><button class="flex flex-1 items-center rounded-md border border-gray-300 bg-white px-2 py-2 text-sm text-black transition-colors hover:border-black hover:bg-black hover:text-white disabled:pointer-events-none disabled:opacity-50 sm:rounded-lg sm:px-4 sm:py-3 sm:text-base"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sparkles mr-1 h-4 text-current" aria-hidden="true"><path d="M9.937 15.5A2 2 0 0 0 8.5 14.063l-6.135-1.582a.5.5 0 0 1 0-.962L8.5 9.936A2 2 0 0 0 9.937 8.5l1.582-6.135a.5.5 0 0 1 .963 0L14.063 8.5A2 2 0 0 0 15.5 9.937l6.135 1.581a.5.5 0 0 1 0 .964L15.5 14.063a2 2 0 0 0-1.437 1.437l-1.582 6.135a.5.5 0 0 1-.963 0z"></path><path d="M20 3v4"></path><path d="M22 5h-4"></path><path d="M4 17v2"></path><path d="M5 18H3"></path></svg>Didn&#x27;t Know that</button><button data-next-question="skip" class="flex flex-1 items-center rounded-md border border-red-600 px-2 py-2 text-sm text-red-600 hover:bg-red-600 hover:text-white disabled:pointer-events-none disabled:opacity-50 sm:rounded-lg sm:px-4 sm:py-3 sm:text-base"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-skip-forward mr-1 h-4" aria-hidden="true"><polygon points="5 4 15 12 5 20 5 4"></polygon><line x1="19" x2="19" y1="5" y2="19"></line></svg>Skip Question</button></div></div><!--astro:end--></astro-island> </div> <h2 id="questions-list">Questions List</h2> <p>
If you prefer to see the questions in a list format, you can find them
        below.
</p> <div class="mb-5"> <h3 id="core-concepts" class="mb-0 capitalize"> Core Concepts </h3> <div class="mb-5"> <h4>What is the difference between correlation and causation?</h4> <div><p>Correlation is the statistical measure that shows a relationship between two variables. When one changes, the other changes as well, positively or negatively. However, this doesn't mean that one variable causes the other to change. Causation means that one variable directly causes a change in the other. It implies a cause-and-effect relationship, not just an association. Proving causation requires deeper analysis and additional evidence.</p>
<p><strong>Example:</strong> There's a correlation between cart abandonment and uninstall rates in a shopping app. Users who abandon their carts often end up uninstalling the app shortly after. But that doesn't mean abandoning a cart causes someone to uninstall the app. The real cause might be a frustrating purchase process with too many steps. That complexity leads to both behaviors: abandoning the cart and uninstalling the app. So, while there's a correlation, you can't say it's causation without looking deeper.</p>
<p><img src="https://assets.roadmap.sh/guest/difference-between-correlation-and-causation-j92us.png" alt="Correlation vs. causation"></p>
</div> </div><div class="mb-5"> <h4>What is the role of statistics in data science?</h4> <div><p>The role of statistics in data science is to help data scientists understand and summarize data, uncover patterns, validate models, handle uncertainty (like missing or noisy data), and make evidence-based decisions.</p>
<p><strong>For example</strong>:</p>
<ul>
<li>Mean and median summarize central tendencies.</li>
<li>Standard deviation and variance measure variability.</li>
<li>Hypothesis testing validates assumptions.</li>
<li>Regression analysis predicts relationships between variables.</li>
<li>Bayesian inference updates beliefs as new data comes in.</li>
</ul>
<p><strong>Use case</strong>: A marketing team runs an A/B test to compare two email campaigns. Statistical methods help determine whether the difference in click-through rates is real or just a coincidence.</p>
</div> </div><div class="mb-5"> <h4>How do you handle missing data?</h4> <div><p>After observing that my data set has missing values, I'll figure out how it occurs. Are they represented as <strong>NaN,</strong> <strong>None,</strong> empty strings, weird characters like -999, a combination of two or more, or something else?</p>
<p><img src="https://assets.roadmap.sh/guest/how-do-you-handle-missing-data-vrptm.png" alt="How to handle missing data"></p>
<p>Once I make sense of what my missing data looks like, I dig into why these values are missing, and they usually fall into three categories:</p>
<ul>
<li>
<p><strong>Missing Completely At Random (MCAR):</strong> No pattern, just random gaps. These are usually safe to drop, especially if there aren't many.</p>
<p><strong>Example:</strong> In a survey dataset, 10% of income entries are missing due to a technical glitch that affected a random subset of responses. There's no pattern based on age, education, employment status, or anything else.</p>
</li>
<li>
<p><strong>Missing At Random (MAR):</strong> This is when the missing data is related to <em>other observed variables</em>, but not to the income value itself.</p>
<p><strong>Example:</strong> In the same dataset, 10% of <code>income</code> values are missing, mostly among respondents who are students. Here, missing data is related to the <code>occupation</code> variable, not the actual income value. Impute based on related features like <code>occupation</code>, <code>education level</code>, or <code>age</code>. Impute based on related features like <code>occupation</code>, <code>education level</code>, or <code>age</code>. Safe to drop or impute with mean/median since the missing data doesn't introduce bias.</p>
</li>
<li>
<p><strong>MNAR (Missing Not At Random):</strong> The reason it's missing is tied to the value itself.</p>
<p><strong>Example:</strong> If high spenders choose not to share income, that's tougher to handle and sometimes better tracked with a missingness flag. The probability of missingness increases with the income amount. Imputation is risky here. I'll consider flagging missingness with a binary indicator (<code>income_missing</code>) or using models that can account for MNAR, like EM algorithms or data augmentation techniques.</p>
</li>
</ul>
<p>Once I know the type of missingness, I choose one of the following:
a. <strong>Deletion (if safe):</strong></p>
<ul>
<li><strong>Listwise:</strong> Drop rows with missing values (only when missingness is random and small).</li>
<li><strong>Pairwise:</strong> Use available values for calculations, such as correlations.</li>
<li><strong>Drop columns:</strong> Remove low-value features with lots of missing data.</li>
</ul>
<p>b.  <strong>Simple imputation:</strong></p>
<ul>
<li><strong>Mean/Median/Mode:</strong> Use for numeric or categorical columns, depending on distribution.</li>
<li><strong>Arbitrary values:</strong> Fill with 0 or &quot;Unknown&quot; if it makes sense contextually.</li>
<li><strong>Forward/Backward fill:</strong> Best for time series to keep temporal consistency.</li>
</ul>
<p>c.  <strong>Advanced imputation:</strong></p>
<ul>
<li><strong>KNN imputer:</strong> Fills gaps by finding similar rows using distance metrics.</li>
<li><strong>Iterative imputer:</strong> Builds a model with other columns to estimate missing values.</li>
<li><strong>Interpolation:</strong> Good for numeric sequences, especially when data follows a trend.</li>
</ul>
<p>d.  <strong>Use missingness as a feature:</strong></p>
<ul>
<li>If the missing value could carry a signal, I add a binary indicator column (e.g., was_missing = 1).</li>
</ul>
<p>e.  <strong>Oversampling or undersampling:</strong></p>
<ul>
<li>If missing data causes class imbalance, I use resampling to maintain a fair target distribution.</li>
</ul>
<p><strong>Common pitfall</strong>:
Filling in values without understanding the pattern of missingness. For example, using mean imputation on MNAR data can introduce bias and weaken your model's predictive power.</p>
</div> </div><div class="mb-5"> <h4>What is the difference between univariate, bivariate, and multivariate analysis?</h4> <div><p>Univariate analysis is all about looking at one variable on its own, with no comparisons, just understanding its distribution, central tendency, or spread. For example, I might look at the average test score in a class or the frequency of different grade ranges using histograms or summary statistics.</p>
<p><img src="https://assets.roadmap.sh/guest/understanding-univariate-bivariate-and-multivariate-analysis-in-data-science-s2663.png" alt="Univariate, bivariate, and multivariate analysis"></p>
<p>Bivariate analysis looks at the relationship between two variables, such as how students' study time affects their test scores. To analyze this, I'd use tools like correlation, scatter plots, or line graphs to identify trends or patterns.</p>
<p>Multivariate analysis, on the other hand, deals with three or more variables at once. It focuses on understanding how multiple factors combine to influence an outcome. For example, I might explore how sleep hours, study time, and caffeine intake together impact test scores. In that case, I'd use regression or a tree-based model to analyze the combined effect.</p>
</div> </div><div class="mb-5"> <h4>What is the difference between the long format data and wide format data?</h4> <div><p>The difference between long format data and wide format data comes down to how your data is structured. A wide format has values that do not repeat in the columns, while a long format has values that do repeat in the columns.</p>
<p>In wide format, you spread data across columns. Each variable (Jan, Feb, March) gets its own column. You'll usually see this in reports or dashboards.</p>
<p><img src="https://assets.roadmap.sh/guest/wide-format-data-gxwrc.png" alt="Wide format data"></p>
<p>In long format, data is stacked in rows. One column stores the values, and another column tells you what those values represent. This format is cleaner for grouped summaries and time series analysis.</p>
<p><img src="https://assets.roadmap.sh/guest/long-format-data-opeyt.png" alt="Long format data"></p>
<p><strong>Use case:</strong> Wide format is useful for reporting and making data visualizations. Long format is preferred for time series, grouped summaries, and plotting tools like Seaborn or ggplot.</p>
<p><strong>Common pitfall:</strong> Trying to perform group-level analysis on wide-format data without reshaping it first.</p>
</div> </div><div class="mb-5"> <h4>What is multicollinearity, and how do you detect it?</h4> <div><p>Multicollinearity is when two or more independent variables in a regression model are highly correlated, meaning they tell similar stories. This makes it hard for the model to figure out which variable is actually influencing the target, leading to unreliable or unstable coefficient estimates.</p>
<p>For example, in a regression model looking at economic growth, common variables will be GDP, Unemployment Rate, and Consumer Spending. These variables are all related, and the model might not be as effective as it should be.</p>
<p><strong>To detect multicollinearity use:</strong></p>
<ul>
<li><strong>Correlation matrix:</strong> A correlation matrix detects multicollinearity by visualizing the strength of relationships between variables. A general rule is that any correlation value above 0.6 indicates strong multicollinearity.</li>
<li><strong>Variance inflation factor (VIF):</strong> VIF detects multicollinearity by giving a numerical value that indicates how much the variance of a regression coefficient is inflated due to multicollinearity. A VIF value greater than 5 indicates moderate multicollinearity, while values above 10 suggest severe multicollinearity.</li>
<li><strong>Condition index:</strong> The condition index is a tool for detecting multicollinearity. Values above 10 indicate moderate multicollinearity, and values above 30 indicate severe multicollinearity. The condition index works by checking how much the independent variables are related to each other by examining the relationships between their eigenvalues.</li>
</ul>
<p><strong>Common pitfall:</strong> Including highly correlated predictors without checking VIF may inflate model error and reduce stability.</p>
</div> </div><div class="mb-5"> <h4>What is variance in data science?</h4> <div><p>Variance in data science measures the spread between numbers in a dataset. Simply put, it measures how far each number in the set is from the mean (average). It helps us understand how spread out or consistent the values are in a dataset.</p>
<p><strong>Low variance example:</strong>
Mean: (78 + 79 + 80 + 81 + 82) / 5 = 80</p>
</div> </div><div class="mb-5"> <h4>What do you understand by imbalanced data?</h4> <div><p>Imbalanced data is a situation where the classes, labels, or categories in a dataset are not equally represented. In imbalanced datasets, one category has significantly more or fewer samples than the others. Imbalanced data refers to a common issue in supervised machine learning and deep learning where there is a non-uniform distribution of samples among different classes. This can lead to biased outcomes in models, such as those used in healthcare services, impacting their reliability and effectiveness.</p>
<p>For example, if you build an email spam detection model and your dataset contains 5% spam emails and 95% non-spam emails, the data is imbalanced toward non-spam. This imbalance can negatively affect the model's performance, especially in production, because it may achieve high accuracy by simply predicting the majority class while failing to detect spam effectively.</p>
</div> </div><div class="mb-5"> <h4>How would you approach categorical and continuous variables differently during preprocessing?</h4> <div><p>A categorical variable is a column with fixed options based on qualities or labels like gender, age group, or education level. You can't do math on them directly, so during preprocessing, I usually apply one-hot encoding to turn those categories into binary columns the model can understand.</p>
<p><img src="https://assets.roadmap.sh/guest/categorical-variable-vs-continuous-variable-m1qz5.png" alt="Categorical vs. continuous variables"></p>
<p>A continuous variable, on the other hand, can take on any value within a range like height, temperature, or speed. These are numeric, so you can run calculations on them. But before feeding them into a model, I scale them using normalization or standardization to keep all features on a similar range. This prevents one feature from overpowering the rest just because it has larger numbers.</p>
</div> </div><div class="mb-5"> <h4>Describe how you would transform data from wide format to long format. Why might this be necessary?</h4> <div><p>To transform data from wide format to long format, I usually use the <strong>melt()</strong> function in pandas to unpivot the columns into rows. It's especially useful when you have repeated measures across columns, like monthly sales or survey responses, and you want to make the data tidy for analysis or plotting.</p>
<p>For example, if I have a DataFrame where each column represents a month, I'll keep the identifier (like product name) as is, and melt the rest so each row shows one product-month-sales combo. This makes it easier to group, filter, or feed into models.</p>
</div> </div><div class="mb-5"> <h4>How do you combine data from multiple sources with inconsistent formats?</h4> <div><p>When I combine data from different sources with inconsistent formats, the first thing I do is standardize everything: dates, column names, booleans, numbers, etc., so they all speak the same language. After doing that, I'll:</p>
<ul>
<li><strong>Align schemas:</strong> match columns across datasets. If one has extras, I drop or keep them depending on relevance.</li>
<li><strong>Unify categories:</strong> I clean up inconsistencies like &quot;Y&quot; vs. &quot;Yes&quot; to avoid downstream issues.</li>
<li><strong>Tag the source:</strong> I add a source column so I know where each row came from. This is super useful for tracking or debugging later.</li>
<li><strong>Merge or stack:</strong> If the structure is the same, I <strong>concat()</strong>. If I'm matching on something like customer ID, I go with a merge or join.</li>
<li><strong>Final clean-up:</strong> I look for duplicates, mismatched types, or broken values post-merge and fix them.</li>
</ul>
<p>I avoid merging before checking data types or keys. That’s a fast track to lost or duplicated rows.</p>
</div> </div> </div><div class="mb-5"> <h3 id="statistics-and-probability" class="mb-0 capitalize"> Statistics and Probability </h3> <div class="mb-5"> <h4>What is the Central Limit Theorem, and why is it important?</h4> <div><p>The Central Limit Theorem (CLT) states that if you take enough random samples from any dataset, even if the data is skewed or messy, the average of those samples will start to form a bell-shaped or normal distribution. This only holds if the samples are random, independent, and large enough, usually 30 or more.</p>
<p>Why does this matter? Because once those averages form a normal shape, you can use all the tools from the normal distribution. You can calculate standard errors, build confidence intervals, run hypothesis tests, make estimates, and use z-scores, even if the original data wasn’t normal to begin with.</p>
</div> </div><div class="mb-5"> <h4>What is the difference between Type I and Type II errors?</h4> <div><p>The difference between Type I and Type II error is that Type I error rejects a true null hypothesis (a false positive), while Type II error fails to reject a false null hypothesis (a false negative).</p>
<p><img src="https://assets.roadmap.sh/guest/difference-between-type-i-and-type-ii-errors-90mpj.png" alt="Type I vs Type II error"></p>
<p>Let's assume you're testing a new drug. The null hypothesis is that the drug doesn't work, and in reality, it indeed doesn't. A type I error occurs when your test says it does, but it doesn't; this is a false positive. A type II, on the other hand, is when the drug works in reality, but your tests say it doesn't: a false negative.</p>
</div> </div><div class="mb-5"> <h4>What is a p-value? How do you interpret it?</h4> <div><p>A p-value is a statistical measure that determines the significance of the result you got in a hypothesis test. A small p-value (&lt;0.05) indicates strong evidence that the null hypothesis is wrong, meaning you should reject it.</p>
<p><img src="https://assets.roadmap.sh/guest/how-to-interpret-p-value-hzfqe.png" alt="P-value interpretation"></p>
<p>If the probability of the p-value is greater than 0.05, there is not enough evidence to reject the null hypothesis. For example, if you conduct an experiment and the p-value is 0.03, you should reject the null hypothesis.</p>
</div> </div><div class="mb-5"> <h4>Explain confidence intervals in simple terms.</h4> <div><p>A confidence interval is a range of values that's likely to have the true value of a population parameter based on sample data. Let's say you surveyed a sample of high school teachers and found their average salary was $75,000. Since that's just a sample, you can't say for sure it reflects all teachers, but we can say:</p>
<p><em>&quot;We're 95% confident that the real average salary for all teachers falls between $72,000 and $78,000.&quot;</em></p>
<p>The confidence interval is between $72,000 and $78,000. It gives us a buffer to account for uncertainty in our estimate.</p>
<p><img src="https://assets.roadmap.sh/guest/confidence-interval-for-teacher-salaries-mee1i.png" alt="Confidence intervals for teachers salaries"></p>
</div> </div><div class="mb-5"> <h4>What is a probability distribution? Name a few commonly used ones.</h4> <div><p>A probability distribution tells you how likely different possible outcomes are for a random event or experiment. It maps out the chances of different results happening. It’s a way of saying, “Here’s everything that could happen, and how often I expect each one to happen.”</p>
<p>The commonly used probability distributions are normal (bell curve), binomial, Poisson, and uniform distributions.</p>
<p><strong>Common pitfall:</strong> Different types of distributions need different types of analysis. Using the wrong type of distribution for analysis can lead to wrong results. Another common problem is assuming that data follow a normal distribution without testing for normality.</p>
</div> </div><div class="mb-5"> <h4>When would you use a t-test vs. a z-test?</h4> <div><p>The difference between a t-test and a z-test comes down to what you know about your data: the sample size and the population standard deviation.</p>
<p><img src="https://assets.roadmap.sh/guest/t-test-vs-z-test-wtm6x.png" alt="t-test vs z-test"></p>
<p>Use a t-test when:</p>
<ul>
<li>The sample size is small (usually n ≤ 30).</li>
<li>The population standard deviation is unknown.</li>
<li>You still want to compare means (sample vs. population or between two samples).</li>
</ul>
<p>Use a z-test when:</p>
<ul>
<li>You know the population standard deviation.</li>
<li>Your sample size is large (typically n &gt; 30).</li>
<li>The data is roughly normally distributed.</li>
</ul>
</div> </div><div class="mb-5"> <h4>What is the null hypothesis, and how do you determine whether to reject it?</h4> <div><p>The null hypothesis (H₀) is the starting point and default assumption of every statistical analysis. The idea is that there's nothing happening in your data: no stories, no effect, no relationship between the variables you're testing until your data gives strong evidence to reject it.</p>
<p><img src="https://assets.roadmap.sh/guest/when-to-reject-null-hypothesis-rchdo.png" alt="When to reject null hypothesis"></p>
<p>To know whether to reject the null hypothesis, here's what I do:</p>
<p>First, I set a significance level, usually 0.05. Then, I calculate the p-value. If the p-value is less than or equal to 0.05, I reject the null hypothesis because the result is statistically significant. If it's more than 0.05, I don't reject it because there isn't enough evidence.</p>
</div> </div><div class="mb-5"> <h4>Explain the Central Limit Theorem if we don&#39;t assume that the random variables are identically distributed but are still independent with finite second moments.</h4> <div><p>This is a curveball question because the interviewer isn't really asking about the classic CLT. They're testing your knowledge about the Lindeberg-Feller CLT.</p>
<p>In the classic CLT, all the variables are independent and from the same probability distribution (identically distributed). But here, the interviewer is saying: What if they're still independent but not identically distributed? Lindeberg-Feller helps in situations like this.</p>
<p>It states that as long as the variables are independent, have finite second moments (meaning their variances aren't huge), and no single variable dominates (the Lindeberg condition), the normalized sum of those variables will still approach a normal distribution. So, even with different distributions, if those conditions hold, the average still forms a bell curve.</p>
</div> </div><div class="mb-5"> <h4>Explain the long-tail distribution and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?</h4> <div><p>A long-tail distribution is a type of distribution where you group most of the data around the middle, but there are still many rare or unusual values that stretch far out to the sides (tail) and have a big impact.</p>
<p><img src="https://assets.roadmap.sh/guest/the-long-tail-t20gr.png" alt="Long-tail distribution"></p>
<p><strong>Some examples are:</strong></p>
<ol>
<li>
<p><strong>Long-tail keywords in SEO</strong>: A few high-volume keywords (like &quot;shoes&quot;) get massive search volume, but there's a long tail of specific, niche searches (like &quot;waterproof hiking shoes for wide feet&quot;) that collectively make up most of the search traffic. These long-tail keywords aren't often searched for, but they convert well.</p>
</li>
<li>
<p><strong>Book sales</strong>: Bestsellers like <em>Harry Potter</em> dominate the market, but tons of niche books (even classics like <em>Jane Austen</em>) sell steadily in the background. The collective sales of these less popular books often exceed those of the bestsellers.</p>
</li>
<li>
<p><strong>Luxury bags</strong>: A few brands are always trending. However, there's a long list of unique, lesser-known ones that still sell and matter to the market.</p>
</li>
</ol>
<p><strong>Why they're important in classification and regression problems:</strong></p>
<p>Long-tail distributions can throw off model performance because most models are trained on the majority class, the &quot;head,&quot; and ignore rare but important events in the tail. This is risky in cases like fraud detection or churn modeling, where rare events matter most. They also affect Mean Squared Error, which squares the difference between predicted and actual values, so a few extreme errors from tail cases can blow up the score, even if your model does well overall.</p>
<p>Long-tail distributions can create models that are biased toward the majority, skew errors, and cause you to miss rare events that matter. Handling them requires better sampling techniques and using loss functions that properly account for these rare but significant occurrences.</p>
</div> </div> </div><div class="mb-5"> <h3 id="machine-learning-and-algorithms" class="mb-0 capitalize"> Machine Learning and Algorithms </h3> <div class="mb-5"> <h4>What is the difference between supervised, unsupervised, and reinforcement learning?</h4> <div><p>The difference between supervised, unsupervised, and reinforcement learning lies in how the model learns. This table describes their contrasts and common use cases for each.</p>
<table>
<thead>
<tr>
<th><strong>Type of Learning</strong></th>
<th><strong>Description</strong></th>
<th><strong>Common Use Cases</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Supervised Learning</strong></td>
<td>Models are trained on labeled data, where each example includes an input and a known output. The model learns to predict the output for new, unseen inputs.</td>
<td>Regression and classification tasks.</td>
</tr>
<tr>
<td><strong>Unsupervised Learning</strong></td>
<td>Models are trained on unlabeled data. The goal is to find hidden patterns or structure in the data without explicit output labels.</td>
<td>Clustering, dimensionality, and reduction tasks.</td>
</tr>
<tr>
<td><strong>Reinforcement Learning</strong></td>
<td>A model learns by trial and error, receiving rewards or penalties based on its actions. It aims to make a sequence of decisions to maximize reward over time.</td>
<td>Games, robotics, and AI decision-making systems.</td>
</tr>
</tbody>
</table>
</div> </div><div class="mb-5"> <h4>Explain the bias-variance tradeoff.</h4> <div><p>The bias-variance tradeoff refers to the balance between a model's ability to learn patterns (low bias) and its ability to generalize to new data (low variance). Bias is the error made when the model makes strong assumptions about the data: high bias could lead to underfitting. Variance is the model's sensitivity to small fluctuations in the data, and high variance could lead to overfitting.</p>
<p><img src="https://assets.roadmap.sh/guest/bias-variance-tradeoff-jc0mj.png" alt="Bias-variance tradeoff"></p>
</div> </div><div class="mb-5"> <h4>What is cross-validation, and why is it important?</h4> <div><p>Cross-validation is a technique for evaluating a model's performance on an individual dataset. It divides the dataset into subsets, usually the training, test, and validation sets. This process is repeated multiple times to ensure the model generalizes well to unseen data and to stop overfitting.</p>
<p><img src="https://assets.roadmap.sh/guest/cross-validationing-data-uha2b.png" alt="Cross-validating data"></p>
</div> </div><div class="mb-5"> <h4>What is overfitting, and how can you prevent it?</h4> <div><p>Overfitting in machine learning happens when the model learns from the training data too well, including non-relevant details. This leads the model to perform very well on the training data but poorly on other data.</p>
<p><strong>Prevention techniques:</strong></p>
<ul>
<li><strong>Regularization (L1/L2):</strong> This method adds a penalty to large weights to keep the model from becoming too complex.</li>
<li><strong>Cross-validation:</strong> This helps test the model on different slices of data to make sure it generalizes well.</li>
<li><strong>Pruning (for tree models):</strong> Cuts back unnecessary branches that overcomplicate the model.</li>
<li><strong>Early stopping:</strong> Stops training when performance stops improving on the validation set.</li>
<li><strong>Dropout (for neural nets):</strong> This method randomly drops neurons during training so the network doesn't become too dependent on specific paths.</li>
</ul>
</div> </div><div class="mb-5"> <h4>How do decision trees work?</h4> <div><p>A decision tree is a machine learning algorithm used for classification and regression tasks. It makes decisions by following a tree-like structure where internal nodes represent attribute tests, branches represent attribute values, and leaf nodes represent predictions.</p>
<p><img src="https://assets.roadmap.sh/guest/decision-tree-y4hrk.png" alt="Decision tree"></p>
<p>Decision trees are versatile and are used for many machine learning tasks.</p>
<p><strong>Example</strong>: Loan approval decision tree</p>
<ul>
<li><strong>Step 1 – Ask a question (Root Node)</strong>: Is the applicant's credit score &gt; 700?
<ul>
<li>If yes, go to Internal Node.</li>
<li>If no, go to Leaf Node (Do not approve the loan).</li>
</ul>
</li>
<li><strong>Step 2 – More questions (Internal Nodes)</strong>: Is the applicant's income &gt; $50,000?
<ul>
<li>If yes, approve the loan (Leaf Node).</li>
<li>If no, go to Leaf Node (Do not approve the loan).</li>
</ul>
</li>
<li><strong>Step 3 - Decision (Leaf Node)</strong>
<ul>
<li>Leaf Node 1: Do not approve the loan (if credit score ≤ 700).</li>
<li>Leaf Node 2: Approve the loan (if credit score &gt; 700 and income &gt; $50,000).</li>
<li>Leaf Node 3: Do not approve the loan (if credit score &gt; 700 and income ≤ $50,000).</li>
</ul>
</li>
</ul>
<p><strong>Common pitfall:</strong> Trees tend to overfit the data if you allow it to go too deep and include too many branches.</p>
</div> </div><div class="mb-5"> <h4>How does a random forest differ from a decision tree?</h4> <div><p>This table describes the difference between decision trees and random forests and when to use them based on features like accuracy, training time, etc.</p>
<p><img src="https://assets.roadmap.sh/guest/random-forest-vs-decision-tree-e8js9.png" alt="Decision tree vs random forest"></p>
<p>A random forest is a collection of multiple decision trees, while a decision tree is just a single model that predicts outcomes based on a series of decisions. For a random forest, each tree is trained on a subset of the data and a subset of features, and both of these are random. A decision tree is a simple, tree-like structure used to represent decisions and the possible outcomes from them. Random forest multiple trees use bootstrapped samples and random feature selection, then average predictions to improve accuracy and reduce overfitting.</p>
</div> </div><div class="mb-5"> <h4>How does logistic regression work?</h4> <div><p>Logistic regression is a supervised machine learning algorithm commonly used for binary classification tasks by predicting the probability of an outcome, event, or observation. The model delivers a binary outcome limited to two possible outcomes: yes/no, 0/1, or true/false. Logical regression analyzes the relationship between one or more independent variables and classifies the data into discrete classes. This relationship is then used to predict the value of one of those factors, the probability of a binary outcome using the logistic (sigmoid) function. It is mostly used for predictive modeling.</p>
<p>For example, 0 represents a negative class, and 1 represents a positive class. Logistic regression is commonly used in binary classification problems where the outcome variable reveals either of the two categories (0 and 1).</p>
<p><strong>Common pitfall:</strong> Misunderstanding that logistic regression is not a classification algorithm but a probability estimator.</p>
</div> </div><div class="mb-5"> <h4>What is linear regression, and what are the different assumptions of linear regression algorithms?</h4> <div><p>Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It is a type of supervised machine learning algorithm that computes the linear relationship between the dependent variable and one or more independent features by fitting a linear equation with observed data. It predicts the output variables based on the independent input variable.</p>
<p>For example, if you want to predict someone's salary, you use various factors such as years of experience, education level, industry of employment, and location of the job. Linear regression uses all these parameters to predict the salary as it is considered a linear relation between all these factors and the price of the house.</p>
<p><strong>Assumptions for linear regression include:</strong></p>
<ul>
<li><strong>Linearity:</strong> Linear regression assumes there is a linear relationship between the independent and dependent variables. This means that changes in the independent variable lead to proportional changes in the dependent variable, whether positively or negatively.</li>
<li><strong>Independence of errors:</strong> The observations should be independent from each other, that is, the errors from one observation should not influence another.</li>
<li><strong>Homoscedasticity (equal variance):</strong> Linear regression assumes the variance of the errors is constant across all levels of the independent variable(s). This indicates that the amount of the independent variable(s) has no impact on the variance of the errors.</li>
<li><strong>Normality of residuals:</strong> This means that the residuals should follow a bell-shaped curve. If the residuals are not normally distributed, then linear regression will not be an accurate model.</li>
<li><strong>No multicollinearity:</strong> Linear regression assumes there is no correlation between the independent variables chosen for the model.</li>
</ul>
</div> </div><div class="mb-5"> <h4>What are support vectors in SVM (Support Vector Machine)?</h4> <div><p>A Support Vector Machine (SVM) is a supervised machine learning algorithm used mainly for classification tasks. It finds the optimal hyperplane in an N-dimensional space that separates data points into different classes while maximizing the margin between the closest points of each class.</p>
<p>Support vectors are the most important data points, useful in defining the optimal hyperplane that separates different classes.</p>
</div> </div><div class="mb-5"> <h4>What is the difference between KNN and K-means?</h4> <div><p>KNN stands for K-nearest neighbors is a classification (or regression) algorithm that, to determine the classification of a point, combines the classification of the K nearest points. It is <strong>supervised</strong> because you are trying to classify a point based on the known classification of other points.</p>
<p><strong>K-means</strong> is a clustering algorithm that tries to partition a set of points into K sets (clusters) such that the points in each cluster tend to be near each other. It is <strong>unsupervised</strong> because the points have no external classification.</p>
<p><img src="https://assets.roadmap.sh/guest/knn-vs-k-means-iqkbo.png" alt="KNN vs. K-means"></p>
<p>This table shows the difference between KNN and K-means depending on the use case, data usage, purpose, and other features.</p>
<table>
<thead>
<tr>
<th><strong>Feature</strong></th>
<th><strong>K-Nearest Neighbors (KNN)</strong></th>
<th><strong>K-Means Clustering</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Algorithm Type</strong></td>
<td>Supervised Learning (Classification/Regression)</td>
<td>Unsupervised Learning (Clustering)</td>
</tr>
<tr>
<td><strong>Purpose</strong></td>
<td>Classifies new data points on labeled training data</td>
<td>Groups unlabeled data points into clusters</td>
</tr>
<tr>
<td><strong>Data Usage</strong></td>
<td>Uses the entire dataset for predictions</td>
<td>Splits the data into clusters iteratively</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Slow for large datasets because all data points are needed for predictions</td>
<td>Faster for large datasets because initial centroids are already set</td>
</tr>
<tr>
<td><strong>Example Use Case</strong></td>
<td>Image Classification, Recommendation Systems</td>
<td>Customer Grouping</td>
</tr>
</tbody>
</table>
</div> </div><div class="mb-5"> <h4>What&#39;s the difference between bagging and boosting?</h4> <div><p>Ensemble techniques in machine learning combine multiple weak models into a strong, more accurate predictive model, using the collective intelligence of diverse models to improve performance. Bagging and boosting are different ensemble techniques that use multiple models to reduce error and optimize the model.</p>
<p><img src="https://assets.roadmap.sh/guest/difference-between-bagging-and-boosting-4j47l.png" alt="Bagging vs. boosting"></p>
<p>The bagging technique uses multiple models trained on different subsets of data. It decreases the variance and helps to avoid overfitting. It is usually applied to decision tree methods and is a special case of the model averaging approach. Boosting is an ensemble modeling technique designed to create a strong classifier by combining multiple weak classifiers. The process involves building models sequentially, where each new model aims to correct the errors made by the previous ones.</p>
<ul>
<li><strong>Bagging:</strong> Builds multiple models in parallel using bootstrapped datasets to reduce variance (e.g., Random Forest).</li>
<li><strong>Boosting:</strong> Builds models sequentially, each trying to correct errors from the previous, reducing bias (e.g., XGBoost).</li>
</ul>
</div> </div><div class="mb-5"> <h4>Compare and contrast linear regression and logistic regression. When would you use one over the other?</h4> <div><p>A linear regression algorithm defines a linear relationship between independent and dependent variables. It uses a linear equation to identify the line of best fit (straight line) for a problem, which it then uses to predict the output of the dependent variables.</p>
<p><img src="https://assets.roadmap.sh/guest/what-is-linear-and-logistic-regression-ipjtz.png" alt="Linear and logistic regression"></p>
<p>A logistic regression algorithm predicts a binary outcome for an event based on a dataset's previous observations. Its output lies between 0 and 1. The algorithm uses independent variables to predict the occurrence or failure of specific events.</p>
<p>You use linear regression when the outcome is a continuous value, such as price or temperature. You should use logistic regression when the outcome is a categorical value like spam/not spam, yes/no, etc.</p>
<p><img src="https://assets.roadmap.sh/guest/linear-vs-logistic-regression-a7cc3.png" alt="Linear vs. logistic regression"></p>
</div> </div><div class="mb-5"> <h4>What is regularization (L1 and L2), and why is it useful?</h4> <div><p>Regularization is a technique in machine learning to prevent models from overfitting. Overfitting happens when a model doesn't just learn from the underlying patterns (signals) in the training data but also picks up and amplifies the noise in it. This leads to a model that performs well on training data but poorly on new data.</p>
<p>L1 and L2 regularization are methods used to mitigate overfitting in machine learning models by adding a penalty term on coefficients to the model's loss function. This penalty discourages the model from assigning too much importance to any single feature (represented by large coefficients), making the model more straightforward. Regularization keeps the model balanced and focused on the true signal, enhancing its ability to generalize to unseen data.</p>
<p>A regression model that uses the L1 regularization technique is called lasso regression, and a model that uses the L2 is called ridge regression.</p>
<ul>
<li><strong>L1 Regularization:</strong> Also called a lasso regression, this adds the absolute value of the sum (&quot;absolute value of magnitude&quot;) of coefficients as a penalty term to the loss function.</li>
<li><strong>L2 Regularization:</strong> Also called a ridge regression, this adds the squared sum (&quot;squared magnitude&quot;) of coefficients as the penalty term to the loss function.</li>
</ul>
</div> </div><div class="mb-5"> <h4>What are precision, recall, F1 score, and AUC-ROC?</h4> <div><p>Once a machine learning model has been created, it is important to evaluate and test how well it performs on data. An evaluation metric is a mathematical quantifier of the quality of the model. Precision, Recall, F1 Score, and AUC-ROC are all evaluation metrics.</p>
<ul>
<li><strong>Precision</strong> is all about how accurate your positive predictions are. Of all the items your model labeled as positive, how many were actually positive?
<strong>Formula = TP / (TP + FP).</strong> It tells you how much you can trust the positives your model finds.</li>
<li><strong>Recall</strong> focuses on finding all the actual positives. It measures how well your model catches everything it should've caught.
<strong>Formula = TP / (TP + FN).</strong> It's especially useful when missing a positive is costly like missing a cancer diagnosis.</li>
<li><strong>F1 Score:</strong> F1 Score combines Recall and Precision into one performance metric. The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. F1 is usually more useful than Accuracy, especially if you have an uneven class distribution.</li>
<li><strong>AUC-ROC:</strong> The AUC-ROC curve is a tool for evaluating the performance of binary classification models. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at different thresholds, showing how well a model can distinguish between two classes, such as positive and negative outcomes. It provides a graphical representation of the model's ability to distinguish between two classes, like a positive class for the presence of a disease and a negative class for the absence of a disease.</li>
</ul>
<p><strong>Key:</strong> TP = True Positive, FP = False Positive, FN = False Negative.</p>
</div> </div><div class="mb-5"> <h4>What is a confusion matrix, and how do you interpret it?</h4> <div><p>A confusion matrix is a simple table that shows how well a classification model is performing by comparing its predictions to the actual results. It breaks down the predictions into four categories: correct predictions for both classes (true positives and true negatives) and incorrect predictions (false positives and false negatives). This helps you understand where the model is making mistakes so you can improve it.</p>
<ul>
<li><strong>TP:</strong> True Positives</li>
<li><strong>TN:</strong> True Negatives</li>
<li><strong>FP:</strong> False Positives</li>
<li><strong>FN:</strong> False Negatives</li>
</ul>
<p><img src="https://assets.roadmap.sh/guest/actual-values-qnezf.png" alt="Confusion matrix"></p>
<p><strong>Example:</strong> From the matrix below, there are 165 total cases:</p>
<ul>
<li><strong>True Negatives:</strong> <strong>50</strong></li>
<li><strong>False Positives:</strong> <strong>10</strong></li>
<li><strong>False Negatives:</strong> <strong>5</strong></li>
<li><strong>True Positives:</strong> <strong>100</strong></li>
</ul>
<p>Depending on the project you're working on, you can use metrics such as Accuracy, Precision, Recall, and F1 Score to evaluate your project. A confusion matrix is a visualization of it.</p>
<p><img src="https://assets.roadmap.sh/guest/sample-confusion-matrix-l4q8i.png" alt="An example of confusion matrix"></p>
<p><strong>Common pitfall:</strong> Misreading the matrix layout or assuming it works for multi-class without modification.</p>
</div> </div><div class="mb-5"> <h4>What feature selection methods do you prefer when building a predictive model? How do you determine which features to keep or discard?</h4> <div><p>When building a predictive model, I like to combine practical steps and proven techniques to ensure that the features I include actually help the model rather than add noise, redundancy, or overfitting risk.</p>
<p><strong>I'll approach like this:</strong></p>
<ol>
<li><strong>Start with domain knowledge:</strong> Talk to stakeholders and review documentation to understand what features make the most sense in our business context.</li>
<li><strong>Use filter methods for a first pass:</strong> I run statistical checks like correlation, ANOVA, chi-square tests, or mutual information to remove irrelevant or redundant features. Filter methods are fast, which is especially helpful when you're working with high-dimensional data.</li>
<li><strong>Apply wrapper methods for performance tuning:</strong> For a more refined selection, I use wrapper methods like Recursive Feature Elimination (RFE). These methods evaluate subsets of features based on how well the model performs, which helps surface the most predictive combinations. They take more time but are worth it for high-impact models.</li>
<li><strong>Leverage embedded methods for efficiency:</strong> Models like Lasso (L1), Ridge (L2), and tree-based models (Random Forest, XGBoost) have built-in feature importance. I like these because they optimize feature selection during model training, balancing speed and accuracy.</li>
<li><strong>Hybrid approach:</strong> Sometimes, I start with a filter method to reduce dimensions and then fine-tune with wrapper or embedded methods. This hybrid approach saves time and improves performance.</li>
</ol>
<p><strong>How I decide what to drop or keep:</strong></p>
<ul>
<li>If a feature is highly correlated with another, I drop the weaker or noisier one.</li>
<li>If it has low variance and no predictive power, it goes.</li>
<li>If it helps interpretability or improves metrics on validation data, I keep it.</li>
<li>If it harms generalization or adds complexity, I drop it.</li>
</ul>
</div> </div><div class="mb-5"> <h4>Explain the difference between false positive and false negative rates in a confusion matrix. How do these metrics impact model evaluation in a fraud detection scenario?</h4> <div><p>False Positive Rate (FPR) is the proportion of actual negatives that are incorrectly identified to be true. False Negative Rate is the proportion of actual positives that are incorrectly identified as negatives.</p>
<p>In a fraud detection scenario, both of these have damaging consequences:</p>
<p><strong>False Positive Rate (FPR)</strong>: If a model has a high false positive rate, it means the system flags many legitimate transactions as fraudulent. This will lead to customer frustration, as their transactions will be flagged regularly, and they could leave.</p>
<p><strong>False Negative Rate (FNR)</strong>: If a model has a high false negative rate, it means many fraudulent transactions are not detected, which could lead to significant financial business loss.</p>
</div> </div> </div><div class="mb-5"> <h3 id="coding-challenges" class="mb-0 capitalize"> Coding Challenges </h3> <div class="mb-5"> <h4>Write an SQL query to get the second-highest salary from an employee table.</h4> <div><p>To find the second highest salary, you can take one of two common methods: a subquery or a window function.</p>
<p><strong>Method 1: Subquery method</strong>
You first get the maximum salary from the table. Then, you find the highest salary that's less than that max, giving you the second highest salary.</p>
<p>This method is clean and efficient:</p>
<pre><code class="language-sql">SELECT MAX(salary) AS SecondHighest
FROM employee
WHERE salary &lt; (SELECT MAX(salary) FROM employee);
</code></pre>
<p><strong>Method 2: Window function with DENSE_RANK()</strong>
You rank all salaries in descending order using DENSE_RANK(), then filter for rank 2 to get the second highest. The LIMIT 1 ensures only one row is returned in case of ties. This method is better for flexibility if you want to choose the third highest or fourth, etc.</p>
<pre><code class="language-sql">SELECT salary AS SecondHighest
FROM (
  SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rank
  FROM employee
) ranked
WHERE rank = 2
LIMIT 1;
</code></pre>
</div> </div><div class="mb-5"> <h4>Joining orders with customer information</h4> <div><p>To join order details with corresponding customer information, you use a simple inner join:</p>
<pre><code class="language-sql">SELECT o.*, c.name, c.email
FROM orders o
JOIN customers c ON o.customer_id = c.id;
</code></pre>
<p>This pulls all orders where a matching customer exists. If you need <strong>every order</strong>, even those without matching customers, switch to a LEFT JOIN:</p>
<pre><code class="language-sql">SELECT o.*, c.name, c.email
FROM orders o
LEFT JOIN customers c ON o.customer_id = c.id;
</code></pre>
</div> </div><div class="mb-5"> <h4>Write an SQL query to find the top 5 customers by revenue.</h4> <div><p>To get the highest-spending customers, group by customer, sum their order totals, sort by that total, and limit the results:</p>
<pre><code class="language-sql">SELECT customer_id, SUM(total_amount) AS revenue
FROM orders
GROUP BY customer_id
ORDER BY revenue DESC
LIMIT 5;
</code></pre>
<p>To add customer names, just join with the customers' table.</p>
<p><strong>Common pitfall:</strong> Not grouping properly before ordering can result in incorrect aggregates.</p>
</div> </div><div class="mb-5"> <h4>Write an SQL query to find the top five customers by purchase amount in the last quarter.</h4> <div><p>To find your top customers <em>who also bought across multiple categories</em>, filter purchases within 3 months, group by customer, and apply category constraints with HAVING:</p>
<pre><code class="language-sql">SELECT customer_id, SUM(amount) AS total_spent
FROM purchases
WHERE purchase_date &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)
GROUP BY customer_id
HAVING COUNT(DISTINCT category_id) &gt;= 3
ORDER BY total_spent DESC
LIMIT 5;
</code></pre>
<p>This makes sure each customer bought from <strong>at least 3 categories</strong>. WHERE filters rows <strong>before</strong> grouping, while HAVING filters groups <strong>after</strong>.</p>
</div> </div><div class="mb-5"> <h4>How do you remove duplicates from a DataFrame?</h4> <div><p>To remove duplicates from a DataFrame:</p>
<pre><code class="language-python">df = df.drop_duplicates()
</code></pre>
<p>You can also refine this by specifying columns:</p>
<pre><code class="language-python"># Drop duplicates based on specific columns
df = df.drop_duplicates(subset=['customer_id', 'product_id'])
</code></pre>
<p>Control which duplicates to keep:</p>
<pre><code class="language-python"># Keep first or last occurrence
df = df.drop_duplicates(keep='last')  # or 'first'
</code></pre>
</div> </div><div class="mb-5"> <h4>Given a stream of data, how would you find the median in real time?</h4> <div><p>To compute the median in a stream of numbers, use two heaps:</p>
<ul>
<li>Max-heap for the lower half</li>
<li>Min-heap for the upper half</li>
<li>Keep both heaps balanced</li>
<li>The median is either the top of one heap or the average of both tops</li>
</ul>
<pre><code class="language-python">import heapq

class MedianFinder:
    def __init__(self):
        self.small = []  # max heap (negative values)
        self.large = []  # min heap
    
    def add_num(self, num):
        if len(self.small) == len(self.large):
            heapq.heappush(self.large, -heapq.heappushpop(self.small, -num))
        else:
            heapq.heappush(self.small, -heapq.heappushpop(self.large, num))
    
    def find_median(self):
        if len(self.small) == len(self.large):
            return (self.large[0] - self.small[0]) / 2.0
        else:
            return self.large[0]
</code></pre>
</div> </div><div class="mb-5"> <h4>Merge overlapping intervals</h4> <div><p>To merge overlapping intervals, first sort them, then iterate and merge as needed:</p>
<pre><code class="language-python">def merge_intervals(intervals):
    intervals.sort(key=lambda x: x[0])
    merged = [intervals[0]]
    for current in intervals[1:]:
        last = merged[-1]
        if current[0] &lt;= last[1]:
            last[1] = max(last[1], current[1])
        else:
            merged.append(current)
    return merged
</code></pre>
<p>Sorting takes O(n log n), and the merge step is linear, making this efficient for large datasets.</p>
</div> </div><div class="mb-5"> <h4>How do you handle null values in pandas?</h4> <div><p>Basic null handling options:</p>
<pre><code class="language-python">df.fillna(0)      # Replace with 0  
df.dropna()       # Drop rows with nulls
</code></pre>
<p>Other methods to consider:</p>
<pre><code class="language-python"># Fill with mean/median/mode
df['column'].fillna(df['column'].mean())
df['column'].fillna(df['column'].median())
df['column'].fillna(df['column'].mode()[0])

# Forward/backward fill
df.fillna(method='ffill')  # Use previous value
df.fillna(method='bfill')  # Use next value

# Interpolation
df.interpolate()
</code></pre>
</div> </div><div class="mb-5"> <h4>How would you group and aggregate data in Python?</h4> <div><p>Basic group and sum:</p>
<pre><code class="language-python">df.groupby('category')['sales'].sum()
</code></pre>
<p>For more complex aggregations:</p>
<pre><code class="language-python"># Multiple aggregations
df.groupby('category').agg({
    'sales': ['sum', 'mean', 'count'],
    'profit': ['min', 'max']
})

# Custom aggregation functions
df.groupby('category')['sales'].agg(lambda x: x.max() - x.min())

# Reset index to convert back to a regular DataFrame
df.groupby('category')['sales'].sum().reset_index()
</code></pre>
</div> </div><div class="mb-5"> <h4>Why does RANK() skip sequence numbers in SQL?</h4> <div><pre><code>Given values: 100, 90, 90, 80
RANK(): Skips ranks after ties
→ 1, 2, 2, 4
DENSE_RANK(): No skipping
→ 1, 2, 2, 3
ROW_NUMBER(): Ignores ties
→ 1, 2, 3, 4
</code></pre>
</div> </div><div class="mb-5"> <h4>Why use a RIGHT JOIN when a LEFT JOIN can suffice?</h4> <div><p>A RIGHT JOIN is the same as a LEFT JOIN with the table order reversed:</p>
<pre><code class="language-sql">SELECT * FROM A RIGHT JOIN B ON A.id = B.id;
SELECT * FROM B LEFT JOIN A ON A.id = B.id;
</code></pre>
</div> </div><div class="mb-5"> <h4>What&#39;s the difference between .apply() and .map() in pandas?</h4> <div><ul>
<li>.map(): Works only on Series, applies a function element-wise</li>
<li>.apply(): More versatile, works on both Series and DataFrames</li>
<li>.applymap(): Applies a function to every element in a DataFrame</li>
</ul>
<pre><code class="language-python"># map - simple transformation of Series values
df['category'] = df['category_id'].map({1: 'Electronics', 2: 'Clothing'})

# apply on Series - more complex operations
df['name'] = df['name'].apply(lambda x: x.title())

# apply on DataFrame - process entire rows or columns
df.apply(lambda x: x.max() - x.min())

# applymap - element-wise operation on entire DataFrame
df.applymap(lambda x: f&quot;{x:.2f}&quot; if isinstance(x, float) else x)
</code></pre>
</div> </div><div class="mb-5"> <h4>How would you implement K-Means clustering in Python?</h4> <div><p><strong>Basic usage:</strong></p>
<pre><code class="language-python">from sklearn.cluster import KMeans  
kmeans = KMeans(n_clusters=3).fit(X)
labels = kmeans.labels_
</code></pre>
<p><strong>Best practices for K-Means:</strong></p>
<pre><code class="language-python"># Scale features
from sklearn.preprocessing import StandardScaler
X_scaled = StandardScaler().fit_transform(X)

# Use elbow method to find optimal k
distortions = []
K_range = range(1, 10)
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    distortions.append(kmeans.inertia_)

# Plot elbow curve
import matplotlib.pyplot as plt
plt.plot(K_range, distortions)
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('Elbow Method For Optimal k')
</code></pre>
</div> </div><div class="mb-5"> <h4>How do you find RMSE and MSE in a linear regression model?</h4> <div><p><strong>To evaluate a regression model:</strong></p>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error  
import numpy as np  
mse = mean_squared_error(y_true, y_pred)  
rmse = np.sqrt(mse)
</code></pre>
<ul>
<li><strong>MSE:</strong> Penalizes large errors heavily.</li>
<li><strong>RMSE:</strong> More interpretable because it's in the same unit as the target.</li>
</ul>
<p><strong>Another alternative:</strong></p>
<pre><code class="language-python">from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
</code></pre>
<p><strong>MAE</strong> is less sensitive to outliers.</p>
</div> </div><div class="mb-5"> <h4>How can you calculate accuracy using a confusion matrix?</h4> <div><pre><code class="language-python">accuracy = (TP + TN) / (TP + TN + FP + FN)
precision = TP / (TP + FP)  # How many selected items are relevant
recall = TP / (TP + FN)     # How many relevant items are selected
f1_score = 2 * (precision * recall) / (precision + recall)  # Harmonic mean

# For imbalanced datasets, consider:
specificity = TN / (TN + FP)
balanced_accuracy = (recall + specificity) / 2
</code></pre>
</div> </div> </div><div class="mb-5"> <h3 id="real-business-scenarios" class="mb-0 capitalize"> Real Business Scenarios </h3> <div class="mb-5"> <h4>How would you measure the success of a new product launch?</h4> <div><p>First, define success for that specific launch. Is it getting 1,000 new users in 30 days? Hitting a revenue or CTR goal? Building awareness in a new market? Or collecting feedback for future improvements?</p>
<p>Once that's clear, measure success using a mix of quantitative and qualitative KPIs across teams like marketing, product, and customer success. Some metrics I'll look at:</p>
<ul>
<li><strong>Launch campaign metrics:</strong> To gauge marketing performance, look at leads generated, channel performance (email, ads, social), website traffic, and press coverage.</li>
<li><strong>Product adoption metrics:</strong> After launch, track trials, usage, activation, and user retention. These show how well the product is landing with your target audience.</li>
<li><strong>Market impact metrics:</strong> Measure business impact through revenue, market share, and win rates against competitors.</li>
<li><strong>Qualitative feedback:</strong> Talk to sales reps, product teams, and customers. Internal and external feedback helps you understand the &quot;why&quot; behind the numbers. Blending data with direct feedback gives you a more transparent, more nuanced view of what's working and what to improve.</li>
</ul>
<p><strong>Common pitfall:</strong> Focusing only on quantitative metrics without applying nuance to them. An example is tracking metrics like downloads without tracking engagement. Or tracking views without knowing who is viewing them.</p>
</div> </div><div class="mb-5"> <h4>You notice a sudden drop in website traffic, how would you investigate it?</h4> <div><p>To analyze a sudden drop in website traffic, I would follow these steps:</p>
<ul>
<li><strong>Determine if it's a drop or a trend:</strong> The first thing to do is try to understand whether your traffic has been declining for a while or if it has suddenly dropped for a day or two.</li>
<li><strong>Rule out any manual actions:</strong> Sometimes, traffic drops happen because of a Google penalty. Check to see if there are any recent changes that you might have fallen foul of. Also, make sure that updates you made to your website's content didn't cause a problem.</li>
<li><strong>Check for algorithm updates:</strong> Google frequently updates its ranking algorithm. When your site's performance drops suddenly, it's worth investigating whether an update might be responsible.</li>
<li><strong>Investigate technical issues:</strong> Some of the most common technical issues are indexing errors, site speed, performance, and mobile usability.</li>
<li><strong>Check competitor activity:</strong> Sometimes, traffic dips occur because competitors have stepped up their game. SEO tools like Ahrefs, SEMrush, or Moz help track your competitors' backlinks, keywords, and rankings. Check to see whether your competitors have started outranking you for previously held keywords or launched new content targeting your primary audience.</li>
</ul>
</div> </div><div class="mb-5"> <h4>What if a model is 95% accurate, but the business is unhappy with the results?</h4> <div><p>There could be multiple reasons why a business could be unsatisfied with a model that has high accuracy. Some reasons are:</p>
<ul>
<li><strong>Focusing on the wrong metric:</strong> Sometimes, a model is not optimized for the specific business problem. Its accuracy is tied to the wrong thing. For example, in fraud detection, it is possible to still miss fraudulent transactions even with high accuracy scores.</li>
<li><strong>Unrealistic expectations:</strong> The model might have unrealistic expectations placed on it to solve problems when, in reality, it is meant to be used in conjunction with other methods and metrics to give a nuanced view.</li>
<li><strong>Overfitting:</strong> It is possible that the high accuracy comes from the model learning the training data rather than learning how to generalize.</li>
</ul>
<p><strong>To handle this problem, I'll:</strong></p>
<ul>
<li><strong>Reevaluate the business goals:</strong> Sometimes, the business goals need to be defined so that there is a specific metric or group of metrics for the model to be trained towards.</li>
<li><strong>Improve the model performance:</strong> You should do a deep dive into the model and fix any issues that you might notice, including overfitting, data issues or feature selection.</li>
</ul>
</div> </div><div class="mb-5"> <h4>You&#39;re given a random dataset, how do you check if it&#39;s useful?</h4> <div><p>To check the quality of a random dataset, I'll:</p>
<ul>
<li>
<p><strong>Understand the problem context:</strong> The first thing to do is to make sure you understand the goal you aim to achieve before looking at the dataset. This allows you to know from first glance whether the dataset matches the problem. If the data has irrelevant columns, you should remove them.</p>
</li>
<li>
<p><strong>Test the data quality:</strong> For any problem you are solving, it has most likely been solved before. You can test your dataset against a trusted dataset to measure any deviations that might be in the data. The dataset also needs to represent real-world scenarios.</p>
</li>
<li>
<p><strong>Technical checks:</strong> With technical checks, it's good to remove duplicates in the data. Noise could be present with blurry images or mislabeled samples. You also have to make sure everything is formatted correctly in a consistent format.</p>
</li>
<li>
<p><strong>Assess practical utility:</strong> The dataset has to be big enough for what you need it to do. For traditional machine learning, the dataset should be more than 10 times greater than the number of features per class. For deep learning, you should aim for 100 features per class to help avoid overfitting.</p>
</li>
</ul>
<p>A dataset is only useful when it aligns with the problem's context and goals. It must pass accuracy, completeness, and balance checks. Finally, it must meet size and representative requirements.</p>
</div> </div><div class="mb-5"> <h4>How would you evaluate a classification model for medical diagnosis?</h4> <div><p>Healthcare classification models use machine learning to analyze vast amounts of patient data. They identify complex patterns and relationships, helping healthcare professionals predict health risks more accurately. These models help doctors make the right decision and reduce diagnostic errors. To evaluate classification models, you have to know the right metrics to use.</p>
<ul>
<li><strong>Accuracy, sensitivity, and specificity metrics</strong>: Accuracy, sensitivity, and specificity are critical in evaluating medical models. Accuracy measures the overall correctness of predictions. Sensitivity, or recall, shows the model's ability to identify positive cases. Specificity indicates how well it identifies negative cases. These metrics are vital for diagnostic accuracy assessment in various medical fields.</li>
<li><strong>ROC curves and AUC analysis</strong>: ROC curves and AUC analysis are key metrics for healthcare AI performance. They evaluate a model's ability to distinguish between classes at different thresholds. A higher AUC score means better performance in distinguishing between positive and negative cases.</li>
<li><strong>Cross-validation techniques</strong>: Cross-validation estimates a model's performance on unseen data. Techniques like k-fold cross-validation split data into subsets for training and testing, providing a robust assessment of the model's ability to generalize.</li>
</ul>
</div> </div><div class="mb-5"> <h4>What is the difference between batch and online learning?</h4> <div><p>Batch learning is a term in artificial intelligence that refers to the process of training a machine learning model on a large set of data all at once, instead of continuously updating the model as new data comes in. This method allows for greater consistency and efficiency in the training process, as the model can learn from a fixed set of data before being deployed for use.</p>
<p>In batch learning, the model sees the entire dataset multiple times (known as epochs), refining its understanding with each pass. By processing data in large chunks, it converges more slowly but generally achieves higher accuracy.</p>
<p>Online learning takes a continuous, incremental approach. Instead of waiting for all the data to be available, you feed it to the model bit by bit, just like learning something new every day instead of cramming for a final exam. The model updates with each new data point, so it's constantly learning and evolving.</p>
<p>For example, imagine you're monitoring customer behavior on a website. Every time a user clicks or makes a purchase, your model gets smarter, learning from that single interaction and refining its predictions for the next.</p>
</div> </div><div class="mb-5"> <h4>What are the pros and cons of deep learning vs. traditional ML?</h4> <div><p><strong>Deep learning</strong> uses multi-layered neural networks to handle complex tasks like image recognition, NLP, and recommendation systems. Think CNNs, RNNs, and Transformers.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Handles complex, high-dimensional data (images, audio, text)</li>
<li>Works with both structured and unstructured data</li>
<li>Learns non-linear relationships</li>
<li>Scales well across use cases with techniques like transfer learning</li>
<li>Great at generalizing from large datasets</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Requires lots of data and compute</li>
<li>Heavily dependent on data quality</li>
<li>Hard to interpret (black box)</li>
<li>Comes with privacy and security concerns</li>
</ul>
<p>Traditional ML uses simpler, more interpretable algorithms like decision trees, logistic regression, and support vector machines.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Works well with smaller datasets</li>
<li>Faster to train and more straightforward to interpret</li>
<li>Lower computational cost</li>
<li>More transparent and explainable</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Struggles with complex/non-linear data</li>
<li>Needs manual feature engineering</li>
<li>Doesn't scale well with large datasets</li>
<li>Can overfit if not tuned properly</li>
</ul>
</div> </div><div class="mb-5"> <h4>How do you monitor model performance in production?</h4> <div><p>You monitor model performance in production by tracking both functional and operational metrics.</p>
<p><strong>Functional monitoring</strong> checks the health of the data and the model:</p>
<ul>
<li><strong>Data quality</strong>: Monitor for missing values, duplicates, and syntax errors.</li>
<li><strong>Data/feature drift</strong>: Compare current input data to training data using stats like KL divergence, PSI, chi-squared, etc.</li>
<li><strong>Model drift</strong>: Check if model accuracy drops over time due to changing patterns in the data.</li>
</ul>
<p><strong>Operational monitoring</strong> keeps the system running smoothly:</p>
<ul>
<li><strong>System health</strong>: Tracks latency, errors, and memory usage.</li>
<li><strong>Input data health</strong>: Watch for type mismatches, nulls, and out-of-range values.</li>
<li><strong>Model performance</strong>: Use precision/recall, RMSE, or top-k accuracy depending on the use case.</li>
<li><strong>Business KPIs</strong>: Tie model performance to actual business outcomes (e.g., conversions, revenue impact).</li>
</ul>
</div> </div> </div><div class="mb-5"> <h3 id="advanced-topics" class="mb-0 capitalize"> Advanced Topics </h3> <div class="mb-5"> <h4>How would you detect concept drift in your model?</h4> <div><p>Concept drift happens when the relationship between your input features and target variable changes over time, causing your model's performance to drop. It's common in dynamic environments (e.g., user behavior, market trends). COVID-19 is a real-world example: models trained pre-pandemic broke down because behavior and data patterns shifted.</p>
<p><strong>How to detect it:</strong></p>
<ul>
<li><strong>Set up reference vs. detection windows:</strong> Compare a stable past dataset (e.g., January traffic) against a current window (e.g., this week). This gives you a baseline.</li>
<li><strong>Compare distributions:</strong> Use statistical tests (e.g., Kolmogorov–Smirnov, PSI, KL divergence) to detect shifts in data or feature distributions.</li>
<li><strong>Track model performance over time:</strong> Drop in precision, recall, or overall accuracy compared to your baseline = red flag.</li>
<li><strong>Run significance tests:</strong> This tells you if the drift is real or just noise.</li>
</ul>
</div> </div><div class="mb-5"> <h4>How do you ensure fairness and remove bias from your models?</h4> <div><p>Fairness means your model makes decisions that don't unfairly favor or penalize any group. Bias can sneak in at any stage, like data collection, labeling, training, and even deployment, so it needs to be addressed early and often.</p>
<p><strong>How to ensure fairness:</strong></p>
<ul>
<li><strong>Start with diverse training data:</strong> Your data should reflect all the groups your model impacts. If it's skewed, the model will be too.</li>
<li><strong>Preprocess to balance representation:</strong> Use techniques like oversampling underrepresented groups or reweighting the data.</li>
<li><strong>Use bias detection tools:</strong> Libraries like Fairlearn, AIF360, and What-If Tool can help you spot performance gaps across subgroups.</li>
<li><strong>Apply fairness constraints during training:</strong> Use regularization, adversarial debiasing, or post-processing adjustments to reduce harm to specific groups.</li>
<li><strong>Build transparency into the model:</strong> Use interpretable models (e.g., decision trees, linear models) or explanation tools like SHAP and LIME.</li>
<li><strong>Audit regularly across subgroups:</strong> Don't rely only on overall accuracy—look at performance across gender, race, age, etc.</li>
<li><strong>Bring in human oversight:</strong> Humans should always be part of the loop, especially in high-stakes decisions (e.g., lending, hiring).</li>
</ul>
</div> </div><div class="mb-5"> <h4>Which is better - specializing a model with fine-tuning or generalizing it with more data?</h4> <div><p>Fine-tuning a model is the process of adapting a pre-trained model for specific tasks or use cases. The reasoning behind fine-tuning is that it is easier and cheaper to improve the capabilities of a pre-trained base model that has already learned road knowledge about the task than it is to train a new model from scratch.</p>
<p>Generalization is a measure of how your model performs in predicting unseen data. Generalizing with more data is improving the model's ability to make predictions on new data rather than the data it was trained on.</p>
<p>Choosing whether to generalize with more data or fine-tune to achieve your goal depends on the specific situation.</p>
<p><strong>For specialization with fine-tuning:</strong></p>
<ul>
<li>It is better when high performance is needed on a very specific task or domain.</li>
<li>It is more efficient to use when you have limited resources, but good data for a specific task.</li>
<li>It can achieve strong results with smaller models.</li>
</ul>
<p><strong>For generalization with more data:</strong></p>
<ul>
<li>It is better for models that need to handle a wide range of tasks.</li>
<li>It is great for situations where overfitting will be a problem.</li>
</ul>
</div> </div> </div> </div> </div> </article>  <div> <div class="bg-slate-900 py-6 pb-10 text-white sm:py-16"> <div class="container"> <p class="mb-8 flex flex-col justify-center gap-0 font-medium text-gray-400 sm:mb-16 sm:flex-row sm:gap-4"> <a class="border-b border-b-gray-700 px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="/roadmaps">Roadmaps</a> <a class="border-b border-b-gray-700 px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="/best-practices">Best Practices</a> <a class="border-b border-b-gray-700 px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="/guides">Guides</a> <a class="border-b border-b-gray-700 px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="/videos">Videos</a> <a class="border-b border-b-gray-700 px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="/about">FAQs</a> <a class="px-2 py-1.5 transition-colors hover:text-white sm:border-b-0 sm:px-0 sm:py-0" href="https://youtube.com/theroadmap?sub_confirmation=1" target="_blank">YouTube</a> </p> <div class="flex flex-col justify-between gap-8 lg:flex-row lg:gap-2"> <div class="max-w-[425px]"> <p class="text-md flex items-center"> <a class="inline-flex items-center text-lg font-medium text-white transition-colors hover:text-gray-400" href="/"> <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 283 283" fill="#000" xmlns:v="https://vecta.io/nano"><path fill="#fff" d="M0 39C0 17.46 17.46 0 39 0h205c21.539 0 39 17.46 39 39v205c0 21.539-17.461 39-39 39H39c-21.54 0-39-17.461-39-39V39Z"></path><path d="M121.215 210.72c-1.867.56-4.854 1.12-8.96 1.68-3.92.56-8.027.84-12.32.84-4.107 0-7.84-.28-11.2-.84-3.174-.56-5.88-1.68-8.12-3.36s-4.014-3.92-5.32-6.72c-1.12-2.987-1.68-6.813-1.68-11.48v-84c0-4.293.746-7.933 2.24-10.92 1.68-3.173 4.013-5.973 7-8.4s6.626-4.573 10.92-6.44c4.48-2.053 9.24-3.827 14.28-5.32a106.176 106.176 0 0 1 15.68-3.36 95.412 95.412 0 0 1 16.24-1.4c8.96 0 16.053 1.773 21.28 5.32 5.226 3.36 7.84 8.96 7.84 16.8 0 2.613-.374 5.227-1.12 7.84-.747 2.427-1.68 4.667-2.8 6.72a133.1 133.1 0 0 0-12.04.56c-4.107.373-8.12.933-12.04 1.68s-7.654 1.587-11.2 2.52c-3.36.747-6.254 1.68-8.68 2.8v95.48zm45.172-22.4c0-7.84 2.426-14.373 7.28-19.6s11.48-7.84 19.88-7.84 15.026 2.613 19.88 7.84 7.28 11.76 7.28 19.6-2.427 14.373-7.28 19.6-11.48 7.84-19.88 7.84-15.027-2.613-19.88-7.84-7.28-11.76-7.28-19.6z"></path></svg> <span class="ml-2">HNM Devs</span> </a> <span class="mx-2 text-gray-400">by</span> <a class="font-regular rounded-md bg-blue-600 px-1.5 py-1 text-sm hover:bg-blue-700" href="https://x.com/hnmdevs" target="_blank"> <span class="hidden sm:inline">@hnmdevs</span> <span class="inline sm:hidden">@hnmdevs</span> </a> </p> <p class="my-4 text-slate-300/60">
Community created roadmaps, best practices, projects, articles,
          resources and journeys to help you choose your path and grow in your
          career.
</p> <div class="text-sm text-gray-400"> <p>
&copy; HNM Devs
<span class="mx-1.5">&middot;</span> <a href="/terms" class="hover:text-white">Terms</a> <span class="mx-1.5">&middot;</span> <a href="/privacy" class="hover:text-white">Privacy</a> <span class="mx-1.5">&middot;</span> <a aria-label="Follow on LinkedIn" href="https://www.linkedin.com/company/hnmdevs" class="hover:text-white" target="_blank"> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="inline-block h-5 w-5 fill-current">
    <g clip-path="url(#clip0_2344_20)">
        <path d="M0 0V24H24V0H0ZM8 19H5V8H8V19ZM6.5 6.732C5.534 6.732 4.75 5.942 4.75 4.968C4.75 3.994 5.534 3.204 6.5 3.204C7.466 3.204 8.25 3.994 8.25 4.968C8.25 5.942 7.467 6.732 6.5 6.732ZM20 19H17V13.396C17 10.028 13 10.283 13 13.396V19H10V8H13V9.765C14.397 7.179 20 6.988 20 12.241V19Z" fill="currentColor"></path>
    </g>
    <defs>
        <clipPath id="clip0_2344_20">
            <rect width="24" height="24" rx="2" fill="white"></rect>
        </clipPath>
    </defs>
</svg> </a> <a aria-label="Subscribe to YouTube channel" href="https://youtube.com/hnmdevs?sub_confirmation=1" target="_blank" class="ml-2 hover:text-white"> <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="currentColor" xmlns:v="https://vecta.io/nano" class="inline-block h-5 w-5"><path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23 0C.488 3.45.029 5.804 0 12c.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23 0C23.512 20.55 23.971 18.196 24 12c-.029-6.185-.484-8.549-4.385-8.816zM9 16V8l8 3.993L9 16z"></path></svg> </a> <a aria-label="Follow on Twitter" href="https://twitter.com/hnmdevs" target="_blank" class="ml-2 hover:text-white"> <svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="100" height="100" viewBox="0 0 50 50" class="inline-block h-5 w-5 fill-current">
<path d="M 6.9199219 6 L 21.136719 26.726562 L 6.2285156 44 L 9.40625 44 L 22.544922 28.777344 L 32.986328 44 L 43 44 L 28.123047 22.3125 L 42.203125 6 L 39.027344 6 L 26.716797 20.261719 L 16.933594 6 L 6.9199219 6 z"></path>
</svg> </a> <a aria-label="Follow on Blusky" href="http://hnmdevs.bsky.social/" target="_blank" class="ml-2 hover:text-white"> <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="Bluesky--Streamline-Simple-Icons" height="24" width="24" class="inline-block h-5 w-5 fill-current"><desc>Bluesky Streamline Icon: https://streamlinehq.com</desc><title>Bluesky</title><path d="M12 10.8c-1.087 -2.114 -4.046 -6.053 -6.798 -7.995C2.566 0.944 1.561 1.266 0.902 1.565 0.139 1.908 0 3.08 0 3.768c0 0.69 0.378 5.65 0.624 6.479 0.815 2.736 3.713 3.66 6.383 3.364 0.136 -0.02 0.275 -0.039 0.415 -0.056 -0.138 0.022 -0.276 0.04 -0.415 0.056 -3.912 0.58 -7.387 2.005 -2.83 7.078 5.013 5.19 6.87 -1.113 7.823 -4.308 0.953 3.195 2.05 9.271 7.733 4.308 4.267 -4.308 1.172 -6.498 -2.74 -7.078a8.741 8.741 0 0 1 -0.415 -0.056c0.14 0.017 0.279 0.036 0.415 0.056 2.67 0.297 5.568 -0.628 6.383 -3.364 0.246 -0.828 0.624 -5.79 0.624 -6.478 0 -0.69 -0.139 -1.861 -0.902 -2.206 -0.659 -0.298 -1.664 -0.62 -4.3 1.24C16.046 4.748 13.087 8.687 12 10.8Z" fill="currentColor" stroke-width="1"></path></svg> </a> </p> </div> </div> <div class="max-w-[340px] text-left lg:text-right"> <a href="https://thenewstack.io" target="_blank"> <img src="/images/tns-sm.png" alt="ThewNewStack" class="my-1.5 mr-auto lg:mr-0 lg:ml-auto" width="200" height="24.8" loading="lazy"> </a> <p class="my-4 text-slate-300/60">
The top DevOps resource for Kubernetes, cloud-native computing, and
          large-scale development and deployment.
</p> <div class="text-sm text-gray-400"> <p> <a href="https://thenewstack.io/category/devops?utm_source=roadmap.sh&utm_medium=Referral&utm_campaign=Footer" target="_blank" class="text-gray-400 hover:text-white">DevOps</a> <span class="mx-1.5">&middot;</span> <a href="https://thenewstack.io/category/kubernetes?utm_source=roadmap.sh&utm_medium=Referral&utm_campaign=Footer" target="_blank" class="text-gray-400 hover:text-white">Kubernetes</a> <span class="mx-1.5">&middot;</span> <a href="https://thenewstack.io/category/cloud-native?utm_source=roadmap.sh&utm_medium=Referral&utm_campaign=Footer" target="_blank" class="text-gray-400 hover:text-white">Cloud-Native</a> </p> </div> </div> </div> <astro-island uid="TcCjc" prefix="r20" component-url="/_astro/CookieSettingsButton.C-tnk8GO.js" component-export="CookieSettingsButton" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;CookieSettingsButton&quot;,&quot;value&quot;:true}" await-children><div class="mt-12 flex items-center justify-start"><button class="flex items-center gap-2 rounded-md bg-slate-800/80 px-3 py-1.5 text-sm text-gray-400 transition-colors hover:bg-slate-700 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-cookie h-4 w-4" aria-hidden="true"><path d="M12 2a10 10 0 1 0 10 10 4 4 0 0 1-5-5 4 4 0 0 1-5-5"></path><path d="M8.5 8.5v.01"></path><path d="M16 15.5v.01"></path><path d="M12 12v.01"></path><path d="M11 17v.01"></path><path d="M7 14v.01"></path></svg>Cookie Settings</button></div><!--astro:end--></astro-island> </div> </div> </div> <script type="module" src="/_astro/Authenticator.astro_astro_type_script_index_0_lang.tx8aIZm1.js"></script>  <script type="module">class n{constructor(){this.triggerPopup=this.triggerPopup.bind(this),this.onDOMLoaded=this.onDOMLoaded.bind(this),this.handleClosePopup=this.handleClosePopup.bind(this),this.handleKeydown=this.handleKeydown.bind(this)}triggerPopup(o){const e=o?.target?.closest("[data-popup]")?.dataset?.popup||"unknown-popup",t=document.querySelector(`#${e}`);if(!t)return;o.preventDefault(),t.classList.remove("hidden"),t.classList.add("flex");const s=t.querySelector("[autofocus]");s&&s.focus()}handleClosePopup(o){const e=o.target,t=e.closest(".popup-body"),s=e.closest(".popup");!e.closest(".popup-close")&&t||s&&(s.classList.add("hidden"),s.classList.remove("flex"))}handleKeydown(o){if(o.key!=="Escape")return;const e=document.querySelector(".popup:not(.hidden)");e&&(e.classList.add("hidden"),e.classList.remove("flex"))}onDOMLoaded(){document.addEventListener("click",this.triggerPopup),document.addEventListener("click",this.handleClosePopup),document.addEventListener("keydown",this.handleKeydown)}init(){window.addEventListener("DOMContentLoaded",this.onDOMLoaded)}}const d=new n;d.init();</script> <div id="login-popup" tabindex="-1" class="hidden bg-black/50 overflow-y-auto overflow-x-hidden fixed top-0 right-0 left-0 z-999 h-full items-center justify-center popup"> <div class="relative p-4 w-full max-w-md h-full md:h-auto"> <div class="relative bg-white rounded-lg shadow-sm popup-body"> <button type="button" class="absolute top-3 right-2.5 text-gray-400 bg-transparent hover:bg-gray-200 hover:text-gray-900 rounded-lg text-sm p-1.5 ml-auto inline-flex items-center popup-close"> <svg aria-hidden="true" class="w-5 h-5" fill="#c6c7c7" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd"
        d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z"
        clipRule="evenodd"></path>
</svg> <span class="sr-only">Close popup</span> </button> <div class="p-5"> <h3 class="text-2xl mb-0.5 font-medium">  </h3> <p class="mb-4 text-sm font-normal text-gray-800">  </p>  <div class="mb-7 text-center"> <p class="mb-3 text-2xl leading-5 font-semibold text-slate-900">
Login or Signup
</p> <p class="mt-2 text-sm leading-4 text-slate-600">
You must be logged in to perform this action.
</p> </div> <astro-island uid="Z12GPPP" prefix="r15" component-url="/_astro/AuthenticationForm.DcPQtuUg.js" component-export="AuthenticationForm" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;AuthenticationForm&quot;,&quot;value&quot;:true}" await-children><div class="flex w-full flex-col gap-2"><button class="inline-flex h-10 w-full items-center justify-center gap-2 rounded-sm border border-slate-300 bg-white p-2 text-sm font-medium text-black outline-hidden hover:border-gray-400 hover:bg-gray-50 focus:ring-2 focus:ring-[#333] focus:ring-offset-1 disabled:cursor-not-allowed disabled:opacity-60"><svg class="h-[18px] w-[18px]" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 98 96"><path fill-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362l-.08-9.127c-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126l-.08 13.526c0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="#24292f"></path></svg>Continue with GitHub</button><button class="inline-flex h-10 w-full items-center justify-center gap-2 rounded-sm border border-slate-300 bg-white p-2 text-sm font-medium text-black outline-hidden hover:border-gray-400 hover:bg-gray-50 focus:ring-2 focus:ring-[#333] focus:ring-offset-1 disabled:cursor-not-allowed disabled:opacity-60"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 90 92" fill="none" class="h-[18px] w-[18px]"><path d="M90 47.1c0-3.1-.3-6.3-.8-9.3H45.9v17.7h24.8c-1 5.7-4.3 10.7-9.2 13.9l14.8 11.5C85 72.8 90 61 90 47.1z" fill="#4280ef"></path><path d="M45.9 91.9c12.4 0 22.8-4.1 30.4-11.1L61.5 69.4c-4.1 2.8-9.4 4.4-15.6 4.4-12 0-22.1-8.1-25.8-18.9L4.9 66.6c7.8 15.5 23.6 25.3 41 25.3z" fill="#34a353"></path><path d="M20.1 54.8c-1.9-5.7-1.9-11.9 0-17.6L4.9 25.4c-6.5 13-6.5 28.3 0 41.2l15.2-11.8z" fill="#f6b704"></path><path d="M45.9 18.3c6.5-.1 12.9 2.4 17.6 6.9L76.6 12C68.3 4.2 57.3 0 45.9.1c-17.4 0-33.2 9.8-41 25.3l15.2 11.8c3.7-10.9 13.8-18.9 25.8-18.9z" fill="#e54335"></path></svg>Continue with Google</button><button class="inline-flex h-10 w-full items-center justify-center gap-2 rounded-sm border border-slate-300 bg-white p-2 text-sm font-medium text-black outline-hidden hover:border-gray-400 focus:ring-2 focus:ring-[#333] focus:ring-offset-1 disabled:cursor-not-allowed disabled:opacity-60"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-[18px] w-[18px] text-blue-700"><g clip-path="url(#clip0_2344_20)"><path d="M0 0V24H24V0H0ZM8 19H5V8H8V19ZM6.5 6.732C5.534 6.732 4.75 5.942 4.75 4.968C4.75 3.994 5.534 3.204 6.5 3.204C7.466 3.204 8.25 3.994 8.25 4.968C8.25 5.942 7.467 6.732 6.5 6.732ZM20 19H17V13.396C17 10.028 13 10.283 13 13.396V19H10V8H13V9.765C14.397 7.179 20 6.988 20 12.241V19Z" fill="currentColor"></path></g><defs><clipPath id="clip0_2344_20"><rect width="24" height="24" rx="2" fill="white"></rect></clipPath></defs></svg>Continue with LinkedIn</button></div><div class="flex w-full items-center gap-2 py-6 text-sm text-slate-600"><div class="h-px w-full bg-slate-200"></div>OR<div class="h-px w-full bg-slate-200"></div></div><form class="w-full"><label for="form:«r15R3»" class="sr-only">Email address</label><input id="form:«r15R3»" type="email" autoComplete="email" required="" class="block w-full rounded-lg border border-gray-300 px-3 py-2 shadow-xs outline-hidden placeholder:text-gray-400 focus:ring-2 focus:ring-black focus:ring-offset-1" placeholder="Email Address" name="email" value=""/><label for="form:«r15R3H1»" class="sr-only">Password</label><input id="form:«r15R3H1»" type="password" autoComplete="current-password" required="" class="mt-2 block w-full rounded-lg border border-gray-300 px-3 py-2 shadow-xs outline-hidden placeholder:text-gray-400 focus:ring-2 focus:ring-black focus:ring-offset-1" placeholder="Password" name="password" value=""/><p class="mt-2 mb-3 text-sm text-gray-500"><a href="/forgot-password" class="text-blue-800 hover:text-blue-600">Reset your password?</a></p><button type="submit" class="inline-flex w-full items-center justify-center rounded-lg bg-black p-2 py-3 text-sm font-medium text-white outline-hidden focus:ring-2 focus:ring-black focus:ring-offset-1 disabled:bg-gray-400">Continue</button></form><!--astro:end--></astro-island> <div class="mt-3 w-full rounded-md border py-2 text-center text-sm text-slate-600">
Don't have an account?  <a href="/signup" class="font-medium text-blue-700 hover:text-blue-600 hover:underline">
Sign up
</a> </div> <div class="mt-3 text-left text-xs leading-normal text-gray-500">By continuing to use our services, you acknowledge that you have both read and agree to our<!-- --> <a href="/terms" class="font-medium underline underline-offset-2 hover:text-black">Terms of Service</a> <!-- -->and<!-- --> <a href="/privacy" class="font-medium underline underline-offset-2 hover:text-black">Privacy Policy</a>.</div>  </div> </div> </div> </div>  <astro-island uid="ZPcbbm" component-url="/_astro/Toast.BXdWWnAU.js" component-export="Toaster" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="only" opts="{&quot;name&quot;:&quot;Toaster&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> <script>(()=>{var l=(n,t)=>{let i=async()=>{await(await n())()},e=typeof t.value=="object"?t.value:void 0,s={timeout:e==null?void 0:e.timeout};"requestIdleCallback"in window?window.requestIdleCallback(i,s):setTimeout(i,s.timeout||200)};(self.Astro||(self.Astro={})).idle=l;window.dispatchEvent(new Event("astro:idle"));})();</script><astro-island uid="1H3NWP" prefix="r14" component-url="/_astro/CommandMenu.CnwD_5VM.js" component-export="CommandMenu" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="idle" opts="{&quot;name&quot;:&quot;CommandMenu&quot;,&quot;value&quot;:true}"></astro-island> <astro-island uid="Z1k5cUN" prefix="r21" component-url="/_astro/PageProgress.BKq1I4D-.js" component-export="PageProgress" renderer-url="/_astro/client.DWEMtbU6.js" props="{&quot;initialMessage&quot;:[0,&quot;&quot;]}" ssr client="idle" opts="{&quot;name&quot;:&quot;PageProgress&quot;,&quot;value&quot;:true}"></astro-island> <astro-island uid="weEH5" component-url="/_astro/GlobalUpgradeModal.C3BxcsvE.js" component-export="GlobalUpgradeModal" renderer-url="/_astro/client.DWEMtbU6.js" props="{}" ssr client="only" opts="{&quot;name&quot;:&quot;GlobalUpgradeModal&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> <div id="div-gpt-ad-1742391132948-0" class="gam-slot fixed bottom-4 right-4 z-50 h-[160px] w-[350px] cursor-pointer max-md:bottom-0 max-md:right-0 max-md:h-[106px] max-md:w-full"> <script type="module">const t=[];function i(e){const n=window.innerWidth<768?"sm":"lg";e.postMessage(`breakpoint:${n}`,"*")}window.addEventListener("resize",()=>{t.forEach(e=>{i(e)})},{passive:!0});window.addEventListener("message",function(e){if(e.data==="initdfp")t.push(e.source),i(e.source);else if(e.data==="close-ad"){const n=document.getElementById("div-gpt-ad-1742391132948-0");n&&n.remove()}});</script> </div> <script type="module">googletag.cmd.push(function(){if(!googletag.pubads){console.log("googletag.pubads not found");return}googletag.pubads().collapseEmptyDivs(),googletag.pubads().setPrivacySettings({restrictDataProcessing:!0,nonPersonalizedAds:!0}),googletag.display("div-gpt-ad-1742391132948-0")});</script>  <astro-island uid="24XVBn" prefix="r22" component-url="/_astro/PageVisit.DsORPinu.js" component-export="PageVisit" renderer-url="/_astro/client.DWEMtbU6.js" props="{&quot;resourceId&quot;:[0],&quot;resourceType&quot;:[0]}" ssr client="load" opts="{&quot;name&quot;:&quot;PageVisit&quot;,&quot;value&quot;:true}"></astro-island> </body></html>